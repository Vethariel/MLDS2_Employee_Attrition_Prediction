{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1BHxJZIl_3Q9",
      "metadata": {
        "id": "1BHxJZIl_3Q9"
      },
      "source": [
        "# **Proyecto aplicado IML - Predicción de rotación de personal**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb4c33d",
      "metadata": {
        "id": "fdb4c33d"
      },
      "source": [
        "# **0. Integrantes del equipo de trabajo**\n",
        "---\n",
        "\n",
        "1. **DANIEL ALONSO GRACIA PINTO**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "240qE0KEBnCT",
      "metadata": {
        "id": "240qE0KEBnCT"
      },
      "source": [
        "# **1. Entendimiento del Negocio y Carga de Datos**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DuFpcI_jAb4e",
      "metadata": {
        "id": "DuFpcI_jAb4e"
      },
      "source": [
        "## **1.1. Marco de Proyecto**\n",
        "---\n",
        "\n",
        "### **1.1.1. Trasfondo del Negocio**\n",
        "---\n",
        "\n",
        "La empresa Automas, especializada en peritajes y asegurabilidad, enfrenta una tasa de rotación de personal del 52% anual (2024), lo cual afecta directamente la eficiencia operativa, los costos asociados a la capacitación de nuevos empleados y la estabilidad organizacional. En este contexto, los beneficiarios del proyecto son tanto el área de talento humano como la gerencia administrativa, al permitir la toma de decisiones estratégicas basadas en datos sobre procesos de contratación, retención y clima organizacional. El proyecto se inscribe dentro del dominio de la analítica de recursos humanos (People Analytics).\n",
        "\n",
        "El objetivo es anticipar la probabilidad de salida temprana, media o prolongada de un nuevo colaborador, permitiendo implementar medidas proactivas de retención basadas en sus características iniciales.\n",
        "\n",
        "### **1.1.2. Alcance**\n",
        "---\n",
        "\n",
        "El proyecto propone construir un modelo de aprendizaje supervisado que permita predecir la duración estimada de permanencia laboral desde el momento del ingreso, tanto de forma categórica como continua:\n",
        "\n",
        "Predicción categórica propuesta:\n",
        "\n",
        " - Salida temprana: 0–90 días\n",
        " - Salida intermedia: 91–180 días\n",
        " - Salida extendida: 181–365 días\n",
        " - Retención prolongada: > 365 días\n",
        "\n",
        "Predicción continua: Tiempo estimado de permanencia en días\n",
        "\n",
        "Incluye:\n",
        "\n",
        " - Información sociodemográfica y contractual inicial\n",
        " - Sede, área, ciudad, nivel del cargo\n",
        " - Salario, edad, distancia al trabajo\n",
        "\n",
        "Excluye:\n",
        "\n",
        " - Factores exógenos no registrados como eventos personales, emergencias Y encuestas de satisfacción laboral\n",
        "\n",
        "Uso esperado del modelo:\n",
        "\n",
        " - Identificación temprana de perfiles con alta probabilidad de rotación\n",
        " - Ajuste de estrategias de onboarding y clima laboral\n",
        " - Apoyo a la toma de decisiones del área de talento humano\n",
        "\n",
        "### **1.1.3. Plan**\n",
        "---\n",
        "El proyecto se estructura en cinco fases conforme a las fechas oficiales de entrega, con una duración estimada de cinco semanas, iniciando el 21 de mayo de 2025. Se estima una disponibilidad de 3 horas semanales, las cuales serán asignadas en función del grado de complejidad de cada fase.\n",
        "\n",
        "A continuación, se presenta la descripción detallada del trabajo por fases:\n",
        "\n",
        "---\n",
        "\n",
        "| Fase | Nombre                            | Semana       | Horas estimadas | Producto esperado                   |\n",
        "| ---- | --------------------------------- | ------------ | --------------- | ----------------------------------- |\n",
        "| 1    | Entendimiento del negocio y carga | 21–27 mayo   | 3 h             | Marco del proyecto + carga de datos |\n",
        "| 2    | Entendimiento de los datos        | 28 may–3 jun | 3–4 h           | Análisis exploratorio (EDA)         |\n",
        "| 3    | Preparación de los datos          | 4–10 junio   | 3 h             | Dataset limpio + variable objetivo  |\n",
        "| 4    | Modelamiento y validación         | 11–15 junio  | 4 h             | Modelos validados y comparados      |\n",
        "| 5    | Evaluación y entrega final        | 16 junio     | 3 h             | Informe final + notebook completo   |\n",
        "\n",
        "Fase 1 – Entendimiento del Negocio y Carga de Datos\n",
        "Semana: 21 al 27 de mayo de 2025\n",
        "Duración estimada: 3 horas\n",
        "\n",
        "Actividades clave:\n",
        "\n",
        "- Definición del problema de negocio: alta rotación de personal y su impacto organizacional.\n",
        "\n",
        "- Establecimiento de objetivos del proyecto: estimar el tiempo de permanencia de nuevos ingresos mediante modelos predictivos (clasificación y regresión).\n",
        "\n",
        "- Revisión del contexto organizacional y análisis de los actores implicados (RRHH, Dirección, líderes de área).\n",
        "\n",
        "- Identificación del tipo de datos disponibles y análisis preliminar del formato y calidad.\n",
        "\n",
        "- Carga del dataset desde Google Drive y conversión a DataFrame para su posterior análisis.\n",
        "\n",
        "Entregables:\n",
        "\n",
        "- Marco del proyecto escrito (trasfondo, alcance, objetivos).\n",
        "\n",
        "- Código funcional de carga de datos desde Google Drive en Colab.\n",
        "\n",
        "Fase 2 – Entendimiento de los Datos\n",
        "Semana: 28 de mayo al 3 de junio de 2025\n",
        "Duración estimada: 3 a 4 horas\n",
        "\n",
        "Actividades clave:\n",
        "\n",
        "- Análisis exploratorio de datos (EDA): revisión de estadísticas descriptivas, tipos de variables y distribución.\n",
        "\n",
        "- Identificación de patrones, outliers y datos faltantes.\n",
        "\n",
        "- Visualización inicial de relaciones entre variables y el tiempo de permanencia.\n",
        "\n",
        "- Revisión de correlaciones entre atributos cuantitativos (salario, edad, distancia) y la variable objetivo.\n",
        "\n",
        "- Análisis cruzado entre variables categóricas y rotación (por ejemplo, sede vs. duración).\n",
        "\n",
        "Entregables:\n",
        "\n",
        "- Informe visual y narrativo de EDA con gráficos descriptivos.\n",
        "\n",
        "- Identificación de variables clave para modelamiento.\n",
        "\n",
        "Fase 3 – Preparación de los Datos\n",
        "Semana: 4 al 10 de junio de 2025\n",
        "Duración estimada: 3 horas\n",
        "\n",
        "Actividades clave:\n",
        "\n",
        "- Limpieza de datos: tratamiento de valores nulos, duplicados o inconsistentes.\n",
        "\n",
        "- Transformación de variables: codificación de variables categóricas, normalización/escalamiento si aplica.\n",
        "\n",
        "- Creación de nuevas variables derivadas: por ejemplo, tiempo entre ingreso y salida, tiempo desde el contrato hasta fecha actual si aún está activo.\n",
        "\n",
        "- Definición de la variable objetivo en términos categóricos y continuos.\n",
        "\n",
        "- Separación de dataset en conjunto de entrenamiento y prueba.\n",
        "\n",
        "Entregables:\n",
        "\n",
        "- Dataset limpio y estructurado para modelamiento.\n",
        "\n",
        "- Variable objetivo preparada para ambos enfoques (clasificación y regresión).\n",
        "\n",
        "Fase 4 – Modelamiento y Validación\n",
        "Semana: 11 al 15 de junio de 2025\n",
        "Duración estimada: 4 horas\n",
        "\n",
        "Actividades clave:\n",
        "\n",
        "- Entrenamiento de modelos supervisados de clasificación: Árboles de Decisión, Random Forest, Regresión Logística, etc.\n",
        "\n",
        "- Entrenamiento de modelos de regresión: Regresión Lineal, Árboles de Regresión, etc.\n",
        "\n",
        "- Validación cruzada y ajuste de hiperparámetros.\n",
        "\n",
        "- Selección de métricas: Accuracy, F1-Score (clasificación), MAE, RMSE (regresión).\n",
        "\n",
        "- Análisis de importancia de variables (feature importance).\n",
        "\n",
        "- Documentación del desempeño comparado entre modelos.\n",
        "\n",
        "Entregables:\n",
        "\n",
        "- Modelos entrenados y validados con desempeño reportado.\n",
        "\n",
        "- Recomendación de modelo óptimo para el problema según criterio de negocio.\n",
        "\n",
        "Fase 5 – Evaluación Final y Presentación de Resultados\n",
        "Semana: 16 de junio de 2025\n",
        "Duración estimada: 3 horas\n",
        "\n",
        "Actividades clave:\n",
        "\n",
        "- Evaluación integral de resultados y validación final sobre el conjunto de prueba.\n",
        "- Análisis de interpretabilidad del modelo.\n",
        "- Generación de recomendaciones de acción para el área de RRHH.\n",
        "- Elaboración de conclusiones y sugerencias para futuras implementaciones (por ejemplo, integración con sistema de contratación).\n",
        "- Revisión final del notebook y entrega formal del proyecto.\n",
        "\n",
        "Entregables:\n",
        "\n",
        "- Notebook completo en Google Colab con narrativa, código y visualizaciones.\n",
        "- Conclusiones estratégicas aplicadas a Automas Comercial LTDA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TMTDWoeqBs2A",
      "metadata": {
        "id": "TMTDWoeqBs2A"
      },
      "source": [
        "## **1.2. Datos**\n",
        "---\n",
        "\n",
        "### **1.2.1. Origen**\n",
        "---\n",
        "\n",
        "Los datos provienen de la base interna de personal de Automas Comercial LTDA, compilada en un archivo Excel por el área de talento humano. Es de acalarar que este archivo presenta un procesamiento previo el cuál se eliminan datos personales de los trabajadores. Contiene registros históricos de empleados, incluyendo sus características de ingreso y su duración en la empresa.\n",
        "\n",
        "Características:\n",
        "\n",
        "Formato: Excel (.xlsx)\n",
        "\n",
        "Origen: Archivo en Google Drive (migrado desde Helisa)\n",
        "\n",
        "Tipo de datos: Mixtos (numéricos, categóricos)\n",
        "\n",
        "Estructura: Un registro por empleado con sus datos iniciales y fecha de salida (si aplica)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S17RrqBQCl2x",
      "metadata": {
        "id": "S17RrqBQCl2x"
      },
      "source": [
        "### **1.2.2. Carga o Adquisición de Datos**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DgiEGZjWm4r7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "DgiEGZjWm4r7",
        "outputId": "793295e3-df4b-4181-b03e-71145755c602"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from datetime import datetime\n",
        "import sklearn\n",
        "import imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "em5rWpbcClPZ",
      "metadata": {
        "id": "em5rWpbcClPZ"
      },
      "outputs": [],
      "source": [
        "url = ''\n",
        "\n",
        "df_personal = pd.read_excel(url, parse_dates= True, engine=\"openpyxl\")\n",
        "\n",
        "df_personal.head()\n",
        "df_personal.info()\n",
        "df_personal.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abeeESHoDAXl",
      "metadata": {
        "id": "abeeESHoDAXl"
      },
      "source": [
        "### **1.2.3. Descripción de Variables Disponibles**\n",
        "---\n",
        "\n",
        "| Variable              | Descripción                                               | Tipo                  | Potencial uso en el modelo                          |\n",
        "| --------------------- | --------------------------------------------------------- | --------------------- | --------------------------------------------------- |\n",
        "| `SUELDO`              | Sueldo base en millones de pesos (MLSV)                   | Numérica continua     | Predictiva: podría correlacionarse con la retención |\n",
        "| `CENTRO_COSTO`        | Código o nombre del centro de costo asignado              | Categórica nominal    | Agrupamiento por unidad funcional                   |\n",
        "| `CARGO`               | Nombre del cargo del empleado                             | Categórica de texto   | Predictiva o para codificación por nivel            |\n",
        "| `FECHA INGRESO`       | Fecha de inicio del contrato laboral                      | Temporal              | Base para calcular permanencia                      |\n",
        "| `FECHA RETIRO`        | Fecha de terminación del contrato (si aplica)             | Temporal              | Base para calcular permanencia                      |\n",
        "| `ACTIVO`              | Indicador de si el colaborador sigue activo               | Binaria (Sí/No)       | Determina si se debe calcular fecha actual          |\n",
        "| `CIUDAD DONDE VIVE`   | Ciudad de residencia del empleado                         | Categórica geográfica | Para cálculo de distancia o análisis regional       |\n",
        "| `FECHA NACIMIENTO`    | Fecha de nacimiento del empleado                          | Temporal              | Para cálculo de edad al ingreso                     |\n",
        "| `SEXO`                | Sexo del colaborador (M/F)                                | Categórica binaria    | Posible segmentación                                |\n",
        "| `LINEA DE NEGOCIO`    | Línea de negocio a la que pertenece                       | Categórica nominal    | Contexto organizacional relevante                   |\n",
        "| `AREA`                | Área funcional o departamento asignado                    | Categórica            | Predictiva                                          |\n",
        "| `TIPO DE CARGO`       | Clasificación del cargo (Operativo, Táctico, Estratégico) | Categórica ordinal    | Predictiva central                                  |\n",
        "| `DISTRIBUCION GLOBAL` | Región global asignada (si aplica)                        | Categórica            | Posible agrupador estructural                       |\n",
        "| `REGIONAL - BSC`      | Región administrativa o subestructura interna             | Categórica            | Para análisis organizacional o clustering           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Xl9Dyf4DJqF",
      "metadata": {
        "id": "-Xl9Dyf4DJqF"
      },
      "source": [
        "### **1.2.4. Variables Derivadas**\n",
        "---\n",
        "\n",
        "| Variable Derivada          | Fuente                                                      | Descripción                                             | Tipo               | Justificación                             |\n",
        "| -------------------------- | ----------------------------------------------------------- | ------------------------------------------------------- | ------------------ | ----------------------------------------- |\n",
        "| `TIEMPO_PERMANENCIA_DIAS`  | `FECHA RETIRO` - `FECHA INGRESO` (o fecha actual si activo) | Total de días que duró (o ha durado) el vínculo laboral | Numérica continua  | Variable objetivo para regresión          |\n",
        "| `CLASE_PERMANENCIA`        | Categorización basada en días de permanencia                | (0–90), (91–180), (181–365), >365                       | Categórica ordinal | Variable objetivo para clasificación      |\n",
        "| `EDAD`                     | A partir de `FECHA NACIMIENTO`                              | Edad al momento de ingreso                              | Numérica           | Posible predictora de retención           |\n",
        "| `DISTANCIA_DOMICILIO_SEDE` | Geolocalización estimada                                    | En kilómetros (requiere geocoding externo)              | Numérica continua  | Predictiva si hay fricción por transporte |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EvY_qcgSM_Fj",
      "metadata": {
        "id": "EvY_qcgSM_Fj"
      },
      "source": [
        "# **2. Entendimiento y Preparación de los Datos**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fwcos36cDWhC",
      "metadata": {
        "id": "Fwcos36cDWhC"
      },
      "source": [
        "\n",
        "\n",
        "## **2.1. Análisis Exploratorio de los Datos**\n",
        "---\n",
        "\n",
        "### **2.1.1. Resumen General**\n",
        "---\n",
        "\n",
        "\n",
        "El conjunto de datos utilizado proviene de un archivo Excel titulado **“PLANTA DE PERSONAL 27-05-2025.xlsx”**, extraído directamente del sistema de recursos humanos interno. Esta fuente es confiable y justificada, ya que representa registros administrativos oficiales de personal.\n",
        "\n",
        "- El archivo contiene **2979 registros** y **12 columnas**, representando empleados actuales e históricos.\n",
        "- Está almacenado en **formato Excel (.xlsx)**, en una sola hoja llamada `CONSULTA`.\n",
        "- El tamaño total es de **0.28 MB**, lo que facilita su análisis en memoria sin requerir procesamiento distribuido.\n",
        "\n",
        "---\n",
        "Además del análisis estructural del dataset, se realizaron varias **transformaciones personalizadas** para mejorar la calidad del análisis y la adecuación del modelo:\n",
        "\n",
        "---\n",
        "#### Cálculo Condicional de la Edad (`EDAD`)\n",
        "- Se incorporó una variable `EDAD` calculada en función del estado laboral del empleado:\n",
        "  - Si el empleado **está activo** (`ACTIVO = \"Sí\"`), la edad se calcula con base en la **fecha actual**.\n",
        "  - Si el empleado **ya no está vinculado** (`ACTIVO = \"No\"`), la edad se calcula en función de la **fecha de retiro**.\n",
        "- Esto permite capturar la edad del individuo en el **momento real de análisis o desvinculación**, ajustando el valor para modelado histórico o prospectivo.\n",
        "---\n",
        "#### Cálculo de la Permanencia (`PERMANENCIA_DIAS` y `PERMANENCIA_RANGO`)\n",
        "- Se derivó el tiempo de permanencia como la diferencia entre `FECHA RETIRO` y `FECHA INGRESO`, exclusivamente para empleados retirados.\n",
        "- Se clasificó dicho valor en la variable categórica `PERMANENCIA_RANGO` con los siguientes intervalos:\n",
        "  - `0–90 días`\n",
        "  - `91–180 días`\n",
        "  - `181–365 días`\n",
        "  - `>365 días`\n",
        "---\n",
        "#### Normalización Salarial (`SUELDO_EN_SM`)\n",
        "- Se creó la variable `SUELDO_EN_SM` para expresar el sueldo en función del salario mínimo legal vigente para el año de referencia.\n",
        "  - Si el empleado **está retirado**, se toma el salario mínimo correspondiente al **año de su retiro**.\n",
        "  - Si está **activo**, se toma el salario mínimo del **año 2025**.\n",
        "- Esto permite normalizar comparativamente los salarios a lo largo del tiempo, ajustando su valor relativo frente al contexto económico.\n",
        "---\n",
        "Estas transformaciones no solo permiten una representación más fiel de la situación de cada empleado, sino que también enriquecen el análisis posterior al ofrecer variables limpias, contextualizadas y aptas para modelos de clasificación y regresión.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bt7x44MVm-O7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "Bt7x44MVm-O7",
        "outputId": "07c91693-fe37-43a3-b786-fe46dc94c59c"
      },
      "outputs": [],
      "source": [
        "# Diccionario de salario mínimo por año (COP)\n",
        "salario_minimo_anual = {\n",
        "    2020: 877803,\n",
        "    2021: 908526,\n",
        "    2022: 1000000,\n",
        "    2023: 1160000,\n",
        "    2024: 1300000,\n",
        "    2025: 1423500\n",
        "}\n",
        "\n",
        "# Función para retornar el salario mínimo correspondiente a un año\n",
        "def salario_minimo_por_año(year):\n",
        "    return salario_minimo_anual.get(year, salario_minimo_anual[2025])\n",
        "\n",
        "# Calcular EDAD ajustada según estado ACTIVO\n",
        "def calcular_edad_condicional(row):\n",
        "    if str(row['ACTIVO']).strip() == 'Si':\n",
        "        referencia = pd.to_datetime(\"today\")\n",
        "    else:\n",
        "        referencia = row['FECHA RETIRO']\n",
        "    if pd.notnull(row['FECHA NACIMIENTO']) and pd.notnull(referencia):\n",
        "        return referencia.year - row['FECHA NACIMIENTO'].year\n",
        "    return None\n",
        "\n",
        "# Limpieza y transformación de fechas\n",
        "df_personal.columns = df_personal.columns.str.strip()\n",
        "df_personal['FECHA INGRESO'] = pd.to_datetime(df_personal['FECHA INGRESO'], errors='coerce')\n",
        "df_personal['FECHA RETIRO'] = pd.to_datetime(df_personal['FECHA RETIRO'], errors='coerce')\n",
        "df_personal['FECHA NACIMIENTO'] = pd.to_datetime(df_personal['FECHA NACIMIENTO'], errors='coerce')\n",
        "\n",
        "# Calcular EDAD\n",
        "df_personal['EDAD'] = df_personal.apply(calcular_edad_condicional, axis=1)\n",
        "\n",
        "# Calcular PERMANENCIA_DIAS\n",
        "df_personal['PERMANENCIA_DIAS'] = (df_personal['FECHA RETIRO'] - df_personal['FECHA INGRESO']).dt.days\n",
        "\n",
        "# Calcular PERMANENCIA_RANGO\n",
        "bins = [-1, 90, 180, 365, float('inf')]\n",
        "labels = ['0–90', '91–180', '181–365', '>365']\n",
        "df_personal['PERMANENCIA_RANGO'] = pd.cut(df_personal['PERMANENCIA_DIAS'], bins=bins, labels=labels, right=True)\n",
        "\n",
        "# Calcular SUELDO_EN_SM\n",
        "def calcular_sueldo_en_sm(row):\n",
        "    if str(row['ACTIVO']).strip() == 'Si':\n",
        "        salario_minimo = salario_minimo_por_año(2025)\n",
        "    else:\n",
        "        año_retiro = row['FECHA RETIRO'].year if pd.notnull(row['FECHA RETIRO']) else 2025\n",
        "        salario_minimo = salario_minimo_por_año(año_retiro)\n",
        "    return round(row['SUELDO'] / salario_minimo, 2) if salario_minimo else None\n",
        "\n",
        "df_personal['SUELDO_EN_SM'] = df_personal.apply(calcular_sueldo_en_sm, axis=1)\n",
        "\n",
        "# Identificar columnas tipo object y convertirlas a category\n",
        "object_cols = df_personal.select_dtypes(include='object').columns\n",
        "df_personal[object_cols] = df_personal[object_cols].astype('category')\n",
        "\n",
        "df_personal.info()\n",
        "df_personal.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RjpbXhV7FHhH",
      "metadata": {
        "id": "RjpbXhV7FHhH"
      },
      "source": [
        "### **2.1.2. Resumen de la Calidad de los datos**\n",
        "---\n",
        "\n",
        "- No se detectaron **documentos vacíos ni duplicados**.\n",
        "- Se identificaron **valores ausentes justificados**, especialmente en `FECHA RETIRO`, `PERMANENCIA_DIAS` y `PERMANENCIA_RANGO`, correspondientes a empleados actualmente activos (`ACTIVO = \"Sí\"`).\n",
        "- La variable `REGIONAL - BSC` presenta un **13% de datos faltantes**, posiblemente atribuibles a vacíos administrativos en ciertas sedes.\n",
        "- El resto de columnas muestra estructura consistente, sin problemas de codificación ni errores de formato.\n",
        "- Se visualizó el porcentaje de valores faltantes por columna para orientar la imputación o exclusión según la relevancia analítica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VntMj9H0FKRT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "VntMj9H0FKRT",
        "outputId": "8ed6c67e-7e1d-442e-b553-46c7e5c97e1e"
      },
      "outputs": [],
      "source": [
        "# Recalcular los valores faltantes por columna\n",
        "missing_values = df_personal.isnull().sum()\n",
        "missing_percent = (missing_values / len(df_personal)) * 100\n",
        "\n",
        "# Filtrar solo columnas con faltantes\n",
        "missing_percent = missing_percent[missing_percent > 0]\n",
        "\n",
        "# Gráfico de barras horizontal\n",
        "plt.figure(figsize=(12, 6))\n",
        "missing_percent.sort_values().plot(kind='barh', color='steelblue')\n",
        "plt.title(\"Porcentaje de Valores Faltantes por Columna\")\n",
        "plt.xlabel(\"Porcentaje (%)\")\n",
        "plt.ylabel(\"Columnas\")\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N4UdkWnrFPM5",
      "metadata": {
        "id": "N4UdkWnrFPM5"
      },
      "source": [
        "### **2.1.3. Tipos de variables**\n",
        "---\n",
        "\n",
        "La variable objetivo `ACTIVO` fue abordada desde tres enfoques distintos:\n",
        "\n",
        "#### a. Clasificación Binaria (`ACTIVO`)\n",
        "- Distribución:\n",
        "  - `No`: 2259 empleados (~75%)\n",
        "  - `Sí`: 756 empleados (~25%)\n",
        "- Existe desbalance que deberá corregirse durante el modelado (por ejemplo, con oversampling o penalización).\n",
        "\n",
        "#### b. Clasificación Multiclase (`PERMANENCIA_RANGO`)\n",
        "- Solo para empleados retirados.\n",
        "- Rango de días de permanencia:\n",
        "  - `0–90 días`: 690 empleados\n",
        "  - `91–180 días`: 351 empleados\n",
        "  - `181–365 días`: 374 empleados\n",
        "  - `>365 días`: 822 empleados\n",
        "- Distribución razonablemente equilibrada. Apta para modelos multiclase.\n",
        "\n",
        "#### c. Regresión (`PERMANENCIA_DIAS`)\n",
        "- Solo para empleados retirados.\n",
        "- Variable continua que permite modelar la duración laboral con precisión.\n",
        "\n",
        "#### Variables adicionales:\n",
        "Además de las variables objetivo (`ACTIVO`, `PERMANENCIA_DIAS`, `PERMANENCIA_RANGO`), el conjunto de datos incluye diversas columnas que pueden actuar como **predictoras** relevantes para los modelos de clasificación o regresión. A continuación se describe cada una:\n",
        "\n",
        "| Variable               | Tipo         | Justificación para inclusión |\n",
        "|------------------------|--------------|-------------------------------|\n",
        "| `SUELDO`               | Numérica     | Indicador socioeconómico. Puede correlacionarse con la duración en el cargo y con el nivel del cargo. Ya ha sido normalizado en múltiplos de salario mínimo (`SUELDO_EN_SM`). |\n",
        "| `EDAD`                 | Numérica     | Factor asociado al ciclo de vida laboral. Se ajustó según fecha de retiro o fecha actual para mejorar precisión contextual. |\n",
        "| `CARGO`                | Categórica   | Refleja el rol funcional. Su análisis permite identificar cargos con mayor o menor retención. Puede requerir codificación por frecuencia o embeddings si el número de categorías es alto. |\n",
        "| `CENTRO_COSTO`         | Categórica   | Se relaciona con unidades presupuestales específicas o sedes. Puede influir en políticas de contratación o rotación. |\n",
        "| `PROCESO`              | Categórica   | Define el macroproceso al que pertenece el cargo. Aporta valor organizacional al modelo. |\n",
        "| `REGIONAL - BSC`       | Categórica   | Segmenta la región geográfica. Posibles diferencias en retención por región deben ser analizadas. |\n",
        "| `SEXO`                 | Categórica   | Puede ser relevante para analizar sesgos o patrones, aunque su uso en modelos debe hacerse con precaución ética. |\n",
        "| `ANTIGUEDAD_DIAS`      | Numérica     | Aporta señal fuerte para clasificación binaria (`ACTIVO`). Se deriva de la fecha de ingreso, aplicable también a activos. |\n",
        "| `FECHA INGRESO`, `FECHA RETIRO` | Fecha | No se usarán directamente, pero sirvieron para derivar variables como `PERMANENCIA_DIAS`, `EDAD` y `ANTIGUEDAD_DIAS`. |\n",
        "\n",
        "---\n",
        "\n",
        "**Variables excluidas o con bajo valor predictivo directo:**\n",
        "- `FECHA NACIMIENTO`: sustituida por `EDAD`.\n",
        "- `NIVEL ORGANIZACIONAL`: si es redundante con `CARGO`, puede eliminarse tras ver su cardinalidad.\n",
        "- `CIUDAD DONDE VIVE`: puede ser redundante con `REGIONAL - BSC`, o utilizada si se hace geocodificación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78vOd1elFbBM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "78vOd1elFbBM",
        "outputId": "4c5289db-e7b4-4379-e311-73e6d8eeff4b"
      },
      "outputs": [],
      "source": [
        "# Gráfico 1: Distribución de la variable binaria ACTIVO\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='ACTIVO', data=df_personal, palette='Set2')\n",
        "plt.title(\"Distribución de la Variable Objetivo Binaria: ACTIVO\")\n",
        "plt.xlabel(\"Estado\")\n",
        "plt.ylabel(\"Número de Empleados\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EjRkY9NsFeQh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "EjRkY9NsFeQh",
        "outputId": "66666846-7519-4c6a-b99e-6d76d1058395"
      },
      "outputs": [],
      "source": [
        "# Gráfico 2: Distribución de rangos de permanencia (solo para no activos)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='PERMANENCIA_RANGO', data=df_personal[df_personal['ACTIVO'].str.strip() == 'No'], palette='Set3', order=['0–90', '91–180', '181–365', '>365'])\n",
        "plt.title(\"Distribución de Rangos de Permanencia (Solo Retirados)\")\n",
        "plt.xlabel(\"Rango de Días de Permanencia\")\n",
        "plt.ylabel(\"Número de Empleados\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6JuJa91zFhzJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "6JuJa91zFhzJ",
        "outputId": "93184e7f-6ace-486a-df79-2e4594ace0f7"
      },
      "outputs": [],
      "source": [
        "# Gráfico 3: Distribución de permanencia en días (Regresión)\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_personal[df_personal['ACTIVO'].str.strip() == 'No']['PERMANENCIA_DIAS'].dropna(), bins=30, kde=True, color='skyblue')\n",
        "plt.title(\"Distribución de PERMANENCIA_DIAS (Solo Retirados)\")\n",
        "plt.xlabel(\"Días de Permanencia\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db-ip8qYFoGK",
      "metadata": {
        "id": "db-ip8qYFoGK"
      },
      "source": [
        "### **2.1.4. Relación Entre Variables**\n",
        "---\n",
        "\n",
        "\n",
        "Para explorar relaciones entre variables se generó una matriz de correlación considerando tanto las variables continuas como variables categóricas transformadas a valores numéricos mediante codificación (`SEXO` y `NIVEL ORGANIZACIONAL`).\n",
        "\n",
        "### Matriz de Correlación\n",
        "\n",
        "Las variables utilizadas fueron:\n",
        "\n",
        "- `EDAD`: edad del empleado, ajustada según fecha de retiro o estado actual.\n",
        "- `SUELDO_EN_SM`: sueldo expresado en múltiplos de salario mínimo.\n",
        "- `PERMANENCIA_DIAS`: días trabajados (solo para retirados).\n",
        "- `ANTIGUEDAD_DIAS`: tiempo desde la fecha de ingreso hasta hoy (activos).\n",
        "- `SEXO_COD`: variable codificada (0 = Femenino, 1 = Masculino, según orden alfabético).\n",
        "- `NIVEL_ORG_COD`: nivel organizacional codificado.\n",
        "\n",
        "#### Principales hallazgos\n",
        "\n",
        "- `PERMANENCIA_DIAS` y `ANTIGUEDAD_DIAS` tienen una **alta correlación (0.73)**, lo cual es esperado ya que ambas reflejan tiempo laboral en distintas condiciones. En un modelo conjunto se recomienda elegir solo una para evitar redundancia.\n",
        "- `EDAD` tiene correlación moderada con:\n",
        "  - `SUELDO_EN_SM` (0.27): sugiere que empleados mayores tienden a tener mejores condiciones salariales.\n",
        "  - `PERMANENCIA_DIAS` (0.25): empleados mayores han permanecido más tiempo antes de salir.\n",
        "- `SUELDO_EN_SM` tiene correlación débil con `PERMANENCIA_DIAS` (0.20), pero casi nula con `ANTIGUEDAD_DIAS` (0.02).\n",
        "- `NIVEL_ORG_COD` muestra una **correlación negativa moderada con `SUELDO_EN_SM` (-0.26)**, lo que sugiere que niveles organizacionales más bajos tienden a tener menores ingresos.\n",
        "- `SEXO_COD` muestra **correlaciones muy bajas con todas las variables**; sin embargo, tiene una ligera correlación positiva con `SUELDO_EN_SM` (0.08), lo que puede indicar una leve diferencia por sexo en los niveles salariales que conviene auditar con más detalle si se busca equidad.\n",
        "\n",
        "Estas observaciones serán clave al momento de seleccionar variables para modelado y garantizar que no exista multicolinealidad significativa ni sesgos estructurales inadvertidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wcl0p-vUF1VF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "wcl0p-vUF1VF",
        "outputId": "b4a1ee18-8639-4364-c162-828193024c8f"
      },
      "outputs": [],
      "source": [
        "# Selección de variables numéricas y transformación de categóricas\n",
        "df_corr = df_personal.copy()\n",
        "\n",
        "# Asegurar tipo numérico para sueldo en SM y edad\n",
        "df_corr['SUELDO_EN_SM'] = pd.to_numeric(df_corr['SUELDO_EN_SM'], errors='coerce')\n",
        "df_corr['EDAD'] = pd.to_numeric(df_corr['EDAD'], errors='coerce')\n",
        "df_corr['ANTIGUEDAD_DIAS'] = (pd.to_datetime(\"today\") - df_corr['FECHA INGRESO']).dt.days\n",
        "\n",
        "# Codificar SEXO y NIVEL ORGANIZACIONAL\n",
        "df_corr['SEXO_COD'] = df_corr['SEXO'].astype('category').cat.codes\n",
        "df_corr['NIVEL_ORG_COD'] = df_corr['NIVEL ORGANIZACIONAL'].astype('category').cat.codes\n",
        "\n",
        "# Variables a correlacionar\n",
        "variables_corr = ['EDAD', 'SUELDO_EN_SM', 'PERMANENCIA_DIAS', 'ANTIGUEDAD_DIAS', 'SEXO_COD', 'NIVEL_ORG_COD']\n",
        "\n",
        "# Eliminar filas con nulos en esas columnas\n",
        "df_corr_valid = df_corr[variables_corr].dropna()\n",
        "\n",
        "# Matriz de correlación\n",
        "corr_matrix = df_corr_valid.corr()\n",
        "\n",
        "# Visualización con mapa de calor\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Matriz de Correlación entre Variables Numéricas y Categóricas Codificadas\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vx0EiNdYF904",
      "metadata": {
        "id": "Vx0EiNdYF904"
      },
      "source": [
        "### **2.1.5. Relación entre Pares de Variables Clave**\n",
        "\n",
        "Se analizaron visualmente relaciones entre variables numéricas y categóricas relevantes para entender mejor su interacción antes del modelado:\n",
        "\n",
        "1. **Edad vs Sueldo en Salarios Mínimos**  \n",
        "   La dispersión muestra una leve correlación positiva: a mayor edad, tiende a haber mayores ingresos. Aunque hay ruido en los datos, esto sugiere que la experiencia acumulada podría estar influyendo en la asignación salarial.\n",
        "\n",
        "2. **Edad vs Días de Permanencia**  \n",
        "   Existe una relación clara: empleados de mayor edad tienden a permanecer más tiempo en la organización. Esto es coherente con trayectorias laborales más estables en perfiles mayores.\n",
        "\n",
        "3. **Nivel Organizacional vs Sueldo**  \n",
        "   Se observa una diferencia significativa de ingreso según el nivel organizacional. Los niveles superiores (codificados con valores mayores) presentan mayores salarios en promedio, con más variabilidad, lo que valida su uso como variable predictora del sueldo.\n",
        "\n",
        "4. **Nivel Organizacional vs Edad**  \n",
        "   También se evidencia que los empleados ubicados en niveles organizacionales más altos tienden a ser mayores. Esto indica que edad y jerarquía están relacionadas y puede implicar una trayectoria de ascenso interna.\n",
        "\n",
        "5. **Días de Permanencia vs Sueldo en Salarios Mínimos**  \n",
        "   La relación muestra una dispersión con ligera tendencia positiva. Si bien no hay una dependencia fuerte, es posible que quienes permanecen más tiempo hayan tenido acceso a mejores condiciones salariales o cargos más estables.\n",
        "\n",
        "Estas visualizaciones respaldan y complementan las correlaciones numéricas, mostrando cómo la edad, el nivel organizacional y el sueldo están interrelacionados. También ayudan a justificar la selección de variables que reflejan estructura interna y trayectoria del empleado como factores importantes en la predicción de permanencia laboral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miTxRXUrGCXb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "miTxRXUrGCXb",
        "outputId": "305b383a-212c-496c-aa93-73722ed8e015"
      },
      "outputs": [],
      "source": [
        "# Gráfico 1: EDAD vs SUELDO_EN_SM\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x='EDAD', y='SUELDO_EN_SM', data=df_corr_valid)\n",
        "plt.title(\"Relación entre Edad y Sueldo (en SM)\")\n",
        "plt.xlabel(\"Edad\")\n",
        "plt.ylabel(\"Sueldo en Salarios Mínimos\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yBVqM8rLGFaP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "yBVqM8rLGFaP",
        "outputId": "81f639f7-1307-4747-a839-80fed37c2ff5"
      },
      "outputs": [],
      "source": [
        "# Gráfico 2: EDAD vs PERMANENCIA_DIAS\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x='EDAD', y='PERMANENCIA_DIAS', data=df_corr_valid)\n",
        "plt.title(\"Relación entre Edad y Días de Permanencia\")\n",
        "plt.xlabel(\"Edad\")\n",
        "plt.ylabel(\"Permanencia (Días)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YQLN4K0qGHzc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "YQLN4K0qGHzc",
        "outputId": "44d1f0ef-5a2f-40ec-d6c8-38dcf99f8cfd"
      },
      "outputs": [],
      "source": [
        "# Gráfico 3: NIVEL_ORG_COD vs SUELDO_EN_SM (boxplot)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(x='NIVEL_ORG_COD', y='SUELDO_EN_SM', data=df_corr_valid)\n",
        "plt.title(\"Sueldo (en SM) por Nivel Organizacional\")\n",
        "plt.xlabel(\"Nivel Organizacional (Codificado)\")\n",
        "plt.ylabel(\"Sueldo en Salarios Mínimos\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QeUKRZtlGKkM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "QeUKRZtlGKkM",
        "outputId": "0d8d4b63-5b5e-496e-da27-d8c1a993906f"
      },
      "outputs": [],
      "source": [
        "# Gráfico 4: EDAD vs NIVEL_ORG_COD\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(x='NIVEL_ORG_COD', y='EDAD', data=df_corr_valid)\n",
        "plt.title(\"Edad por Nivel Organizacional\")\n",
        "plt.xlabel(\"Nivel Organizacional (Codificado)\")\n",
        "plt.ylabel(\"Edad\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y21PMca9GMkz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Y21PMca9GMkz",
        "outputId": "73da3fe7-733c-4096-c213-cf7aeef879e0"
      },
      "outputs": [],
      "source": [
        "# Gráfico adicional: PERMANENCIA_DIAS vs SUELDO_EN_SM\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x='PERMANENCIA_DIAS', y='SUELDO_EN_SM', data=df_corr_valid)\n",
        "plt.title(\"Relación entre Permanencia en Días y Sueldo (en SM)\")\n",
        "plt.xlabel(\"Permanencia en Días\")\n",
        "plt.ylabel(\"Sueldo en Salarios Mínimos\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2lCVczDMGRD1",
      "metadata": {
        "id": "2lCVczDMGRD1"
      },
      "source": [
        "### **2.1.6. Conclusión de fase exploratoria**\n",
        "---\n",
        "\n",
        "El análisis exploratorio permitió validar la calidad del dataset y extraer variables relevantes para modelar la permanencia laboral. Se definieron tres enfoques para la variable objetivo: clasificación binaria (`ACTIVO`), multiclase (`PERMANENCIA_RANGO`) y regresión (`PERMANENCIA_DIAS`), con transformaciones específicas como el ajuste de edad según estado laboral y la normalización del sueldo en salarios mínimos vigentes.\n",
        "\n",
        "Las variables derivadas (`EDAD`, `SUELDO_EN_SM`, `ANTIGUEDAD_DIAS`) mostraron correlaciones moderadas entre sí, aportando señal predictiva sin incurrir en redundancia excesiva. También se identificó una correlación negativa entre nivel organizacional y sueldo, y una leve diferencia salarial por sexo, lo que puede ser relevante desde una perspectiva de equidad.\n",
        "\n",
        "El conjunto de datos es estructurado, coherente y suficientemente rico para avanzar a la fase de preparación y modelamiento con fundamentos sólidos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chw_lKRIGoIc",
      "metadata": {
        "id": "chw_lKRIGoIc"
      },
      "source": [
        "# **3. Preparación de los datos**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ra6nburGsT9",
      "metadata": {
        "id": "1ra6nburGsT9"
      },
      "source": [
        "## **3.1. Limpieza de los Datos**\n",
        "---\n",
        "\n",
        "A continuación se describe el proceso de limpieza y transformación de un conjunto de datos de recursos humanos con el fin de prepararlo para modelos de clasificación y regresión. Se abordarán valores faltantes, duplicados, atípicos e inconsistentes, y se crearán variables derivadas que enriquecen el análisis. Al final, se generarán subconjuntos de datos estructurados y codificados según distintos objetivos predictivos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K13pFVk9G0Hp",
      "metadata": {
        "id": "K13pFVk9G0Hp"
      },
      "source": [
        "### **3.1.1. Valores faltantes**\n",
        "---\n",
        "\n",
        "La limpieza de valores faltantes se abordó desde una perspectiva contextual, evaluando el significado operativo de cada variable en lugar de aplicar reglas genéricas. No todos los valores ausentes son problemáticos: en muchos casos, su ausencia responde a la lógica de negocio, como ocurre con `FECHA RETIRO` o `PERMANENCIA_DIAS` en empleados actualmente activos.\n",
        "\n",
        "Se decidió excluir del análisis la variable `REGIONAL - BSC`, al tratarse de una categoría derivada que no fue parametrizada de forma coherente en el origen de los datos.\n",
        "\n",
        "En cuanto a la variable `FECHA NACIMIENTO`, se detectaron casos con edades inferiores a 17 años, probablemente por errores de digitación. Para garantizar consistencia, todas las fechas de nacimiento faltantes o sospechosas fueron reemplazadas por la media general de las fechas de nacimiento válidas, garantizando una edad plausible y homogénea para estos casos.\n",
        "\n",
        "Por su parte, la columna `CIUDAD DONDE VIVE` fue imputada con base en la ciudad dominante asociada al `CENTRO_COSTO` correspondiente, bajo la hipótesis de que el lugar de trabajo generalmente coincide con el lugar de residencia o al menos permite inferirlo de forma razonable.\n",
        "\n",
        "Este tratamiento diferenciado mejora la coherencia del dataset sin introducir supuestos arbitrarios, y preserva la integridad analítica requerida para las siguientes fases del proyecto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xz0b-HconDC1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz0b-HconDC1",
        "outputId": "807a65a1-4311-40c5-dbac-ae7d85fd2c51"
      },
      "outputs": [],
      "source": [
        "# Calcular promedio de fechas válidas\n",
        "fecha_promedio = df_personal[df_personal['EDAD'] >= 17]['FECHA NACIMIENTO'].mean()\n",
        "\n",
        "# Reemplazar fechas faltantes o edades <17 con la media\n",
        "df_personal.loc[(df_personal['EDAD'] < 17) | (df_personal['FECHA NACIMIENTO'].isnull()), 'FECHA NACIMIENTO'] = fecha_promedio\n",
        "df_personal['EDAD'] = df_personal.apply(calcular_edad_condicional, axis=1)\n",
        "\n",
        "df_personal.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k_eiooATHIqR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_eiooATHIqR",
        "outputId": "ddc4479d-d0c3-42d7-b86b-e06851de362b"
      },
      "outputs": [],
      "source": [
        "# Crear un mapa centro_costo → ciudad más común\n",
        "mapa_ciudad = df_personal.groupby('CENTRO_COSTO')['CIUDAD DONDE VIVE'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
        "\n",
        "# Rellenar con el valor correspondiente\n",
        "df_personal['CIUDAD DONDE VIVE'] = df_personal.apply(\n",
        "    lambda row: mapa_ciudad[row['CENTRO_COSTO']] if pd.isna(row['CIUDAD DONDE VIVE']) else row['CIUDAD DONDE VIVE'],\n",
        "    axis=1\n",
        ")\n",
        "object_cols = df_personal.select_dtypes(include='object').columns\n",
        "df_personal[object_cols] = df_personal[object_cols].astype('category')\n",
        "\n",
        "df_personal.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2wXlDZS6HaUR",
      "metadata": {
        "id": "2wXlDZS6HaUR"
      },
      "source": [
        "### **3.1.2. Valores duplicados**\n",
        "----\n",
        "\n",
        "En el contexto de este conjunto de datos, cada fila representa una trayectoria individual del personal, incluyendo su cargo, ubicación, estado de contratación y fechas clave. Bajo esta premisa, se evaluó cuidadosamente la presencia de duplicados para evitar eliminar registros válidos que correspondan a experiencias laborales distintas, aunque similares en apariencia. La verificación incluyó tanto comparaciones de filas completas como evaluaciones de combinaciones clave como `CARGO`, `FECHA INGRESO` y `CENTRO_COSTO`. No se encontraron duplicados completos ni patrones de repetición que indicaran errores o redundancia estructural. Por tanto, no se realizó ninguna eliminación. Esta decisión garantiza que se preserve la singularidad de cada trayectoria laboral y se respete la integridad histórica del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t3f5CuH8HdFe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3f5CuH8HdFe",
        "outputId": "c96508f4-25b3-4e9a-8864-dec2cbcef192"
      },
      "outputs": [],
      "source": [
        "# Verificar duplicados completos (todas las columnas)\n",
        "duplicados_completos = df_personal.duplicated()\n",
        "total_duplicados_completos = duplicados_completos.sum()\n",
        "print(f\"Registros completamente duplicados: {total_duplicados_completos}\")\n",
        "\n",
        "# Verificar duplicados por subconjunto clave\n",
        "duplicados_subconjunto = df_personal.duplicated(subset=['CARGO', 'FECHA INGRESO', 'CENTRO_COSTO'])\n",
        "total_duplicados_subconjunto = duplicados_subconjunto.sum()\n",
        "print(f\"Registros duplicados por CARGO + FECHA INGRESO + CENTRO_COSTO: {total_duplicados_subconjunto}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0QMtqYKlH6vg",
      "metadata": {
        "id": "0QMtqYKlH6vg"
      },
      "source": [
        "### **3.1.3. Valores atípicos**\n",
        "---\n",
        "\n",
        "En el tratamiento de valores atípicos se reconoció que no todo dato extremo representa un error. En un contexto organizacional, es común encontrar sueldos elevados, edades avanzadas o periodos de permanencia inusualmente largos que, aunque poco frecuentes, corresponden a situaciones reales como cargos directivos, trayectorias laborales extensas o personal con condiciones contractuales especiales. Por ello, se adoptó un enfoque analítico que combina la estadística con la lógica del dominio.\n",
        "\n",
        "Para su identificación, se emplearon métodos visuales como boxplots y histogramas sobre variables continuas clave: `SUELDO`, `SUELDO_EN_SM`, `EDAD`, `PERMANENCIA_DIAS` y `ANTIGÜEDAD_DIAS`. También se utilizaron reglas estadísticas como el rango intercuartílico (IQR) para detectar valores fuera de los rangos típicos. En particular, se encontraron casos con sueldos por encima de 10 millones, edades mayores a 75 años y permanencias superiores a 10 años. Sin embargo, al cruzar estos registros con otras variables como `NIVEL ORGANIZACIONAL` y `ESTADO ACTIVO`, se evidenció que en su mayoría corresponden a perfiles ejecutivos o excepciones justificables.\n",
        "\n",
        "Dado que estos puntos extremos reflejan variabilidad real del entorno laboral y no afectan de forma desproporcionada la estructura global del dataset, se optó por conservarlos sin transformación ni eliminación. Su inclusión fortalece la capacidad del modelo para captar fenómenos no lineales y mejorar la robustez predictiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FFUCdlaaH84h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FFUCdlaaH84h",
        "outputId": "0e9b0653-e15a-4765-cef0-868b2e56f5a2"
      },
      "outputs": [],
      "source": [
        "# Selección de variables numéricas clave para análisis de outliers\n",
        "variables = ['SUELDO', 'SUELDO_EN_SM', 'EDAD', 'PERMANENCIA_DIAS']\n",
        "\n",
        "# Crear boxplots e histogramas para cada variable\n",
        "for var in variables:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Boxplot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.boxplot(x=df_personal[var])\n",
        "    plt.title(f'Boxplot de {var}')\n",
        "    plt.xlabel(var)\n",
        "\n",
        "    # Histograma\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(df_personal[var], kde=True, bins=30)\n",
        "    plt.title(f'Histograma de {var}')\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F2YEGEx-IHQI",
      "metadata": {
        "id": "F2YEGEx-IHQI"
      },
      "source": [
        "### **3.1.4. Datos Inconsistentes**\n",
        "---\n",
        "\n",
        "Durante la fase de exploración se identificaron distintas formas de inconsistencia estructural que, si no se trataban, podrían afectar la comparabilidad entre registros y distorsionar los análisis posteriores. Uno de los primeros ajustes realizados fue la estandarización del `SUELDO`, que originalmente estaba expresado en valores absolutos en pesos colombianos. Esta medida, al no tener en cuenta la inflación ni los cambios anuales en el salario mínimo, podía inducir sesgos al comparar cargos similares en años diferentes. Por ello, se transformó esta variable a `SUELDO_EN_SM`, permitiendo su análisis en términos relativos con base en el salario mínimo legal vigente según el año de retiro o el año actual para empleados activos.\n",
        "\n",
        "Asimismo, se detectó una **alta heterogeneidad en los nombres de los cargos** registrados, lo cual dificultaba el agrupamiento y análisis comparativo. Para mitigar este ruido semántico, se recurrió a variables más estructuradas y confiables: `NIVEL ORGANIZACIONAL` y `PROCESO`, que ofrecen una representación más uniforme del rol funcional de cada colaborador dentro de la organización.\n",
        "\n",
        "En el caso de `CENTRO_COSTO`, se evidenció una falta de estandarización y posible duplicidad semántica (variaciones menores en nombres para el mismo centro operativo). Aunque no se aplicó una limpieza directa sobre esta columna, se definió una estrategia de reemplazo: evaluar la posibilidad de agrupar o reconstruir esta variable a partir de una combinación más robusta y homogénea entre `CIUDAD DONDE VIVE`, `PROCESO` y `NIVEL ORGANIZACIONAL`, lo cual será abordado durante el diseño del modelo.\n",
        "\n",
        "Si bien no se implementaron validaciones automáticas en esta fase, las transformaciones realizadas y las decisiones tomadas reflejan una estrategia clara de saneamiento progresivo, garantizando que la información esté alineada con una lógica de negocio coherente y funcional para el modelado predictivo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cEeSow4XIRpE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cEeSow4XIRpE",
        "outputId": "5e762354-0cbb-4848-f845-bcd83c05ba83"
      },
      "outputs": [],
      "source": [
        "# Comparativa 1: Distribución de CARGO vs NIVEL ORGANIZACIONAL + PROCESO\n",
        "# Agrupaciones\n",
        "cargos_por_proceso = df_personal.groupby('PROCESO')['CARGO'].nunique().sort_values(ascending=False).reset_index()\n",
        "cargos_por_proceso.columns = ['PROCESO', 'CARGOS_UNICOS']\n",
        "\n",
        "cargos_por_nivel = df_personal.groupby('NIVEL ORGANIZACIONAL')['CARGO'].nunique().sort_values(ascending=False).reset_index()\n",
        "cargos_por_nivel.columns = ['NIVEL ORGANIZACIONAL', 'CARGOS_UNICOS']\n",
        "\n",
        "# Visualización: Cargos por Proceso\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='CARGOS_UNICOS', y='PROCESO', data=cargos_por_proceso, palette='Blues_d')\n",
        "plt.title('Cantidad de Cargos Únicos por Proceso')\n",
        "plt.xlabel('Número de Cargos')\n",
        "plt.ylabel('Proceso')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualización: Cargos por Nivel Organizacional\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='CARGOS_UNICOS', y='NIVEL ORGANIZACIONAL', data=cargos_por_nivel, palette='Greens_d')\n",
        "plt.title('Cantidad de Cargos Únicos por Nivel Organizacional')\n",
        "plt.xlabel('Número de Cargos')\n",
        "plt.ylabel('Nivel Organizacional')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hCjHrzBTIXs-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hCjHrzBTIXs-",
        "outputId": "6fadada5-f65c-4582-e3bf-9365d9ffb2ee"
      },
      "outputs": [],
      "source": [
        "# Comparativa 2: Sueldo en pesos vs sueldo en SM por año de retiro o año actual\n",
        "df_personal['AÑO_REFERENCIA'] = df_personal.apply(\n",
        "    lambda row: row['FECHA RETIRO'].year if pd.notnull(row['FECHA RETIRO']) else datetime.today().year,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='AÑO_REFERENCIA', y='SUELDO', data=df_personal)\n",
        "plt.title('Distribución del Sueldo en Pesos por Año de Referencia')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='AÑO_REFERENCIA', y='SUELDO_EN_SM', data=df_personal)\n",
        "plt.title('Distribución del Sueldo en SM por Año de Referencia')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Orif07PpIb6I",
      "metadata": {
        "id": "Orif07PpIb6I"
      },
      "source": [
        "### **3.1.5. Datos corruptos**\n",
        "---\n",
        "\n",
        "Durante el análisis exploratorio y la limpieza inicial del conjunto de datos, se tomaron medidas específicas para detectar y corregir posibles signos de corrupción, entendidos como errores de entrada, formatos no válidos o datos que perdieron integridad durante su transferencia o registro. Aunque no se identificaron campos ilegibles ni codificaciones rotas, sí se observaron valores estructuralmente incoherentes, como fechas de nacimiento que implicaban edades menores a 17 años o nombres de cargos y centros de costo con inconsistencias tipográficas o de nomenclatura.\n",
        "\n",
        "Para mitigar estos casos, se imputaron fechas de nacimiento sospechosas con la media de fechas válidas, lo cual permitió recuperar la coherencia en el cálculo de la edad sin recurrir a eliminación. En cuanto a `CENTRO_COSTO`, si bien no se corrigieron manualmente los valores, se propuso reemplazar su uso por una combinación más robusta de variables (`CIUDAD DONDE VIVE`, `PROCESO`, `NIVEL ORGANIZACIONAL`), evidenciando una estrategia clara de aislamiento y sustitución de campos potencialmente corruptos.\n",
        "\n",
        "No fue necesario eliminar registros, ya que la estructura del dataset se mantuvo íntegra, y los casos detectados como anómalos fueron abordados mediante transformación o imputación. Esta aproximación garantiza la conservación del mayor volumen posible de información sin comprometer la fiabilidad del análisis posterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B3C2pj14IgjI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3C2pj14IgjI",
        "outputId": "c554d4a4-015a-4d59-e48a-f1a81b5cf41e"
      },
      "outputs": [],
      "source": [
        "# Seleccionar columnas categóricas\n",
        "categoric_df = df_personal.select_dtypes(['category'])\n",
        "\n",
        "print('Características categóricas y frecuencia de valores\\n')\n",
        "for col in categoric_df.columns:\n",
        "    print(f'Característica: {col}')\n",
        "    freq = categoric_df[col].value_counts()\n",
        "    for i, (val, count) in enumerate(freq.items()):\n",
        "        print(f\"\\t{i + 1}. {val}: {count} registros\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VXuyA3r7IriU",
      "metadata": {
        "id": "VXuyA3r7IriU"
      },
      "source": [
        "### **3.1.6. Selección de datos**\n",
        "---\n",
        "La selección de variables se fundamentó en su relevancia directa para el objetivo analítico del proyecto: construir modelos predictivos relacionados con la permanencia del personal. Se descartaron aquellas columnas que no aportan valor directo al modelado o que podrían inducir redundancia o ruido estructural.\n",
        "\n",
        "Entre las variables excluidas se encuentran campos de fecha como `FECHA INGRESO`, `FECHA RETIRO` y `FECHA NACIMIENTO`, que ya fueron transformadas en variables derivadas como `PERMANENCIA_DIAS` y `EDAD`. También se excluyó `SUELDO`, dado que se reemplazó por una versión estandarizada (`SUELDO_EN_SM`) que permite comparabilidad interanual, y `REGIONAL - BSC`, por presentar ambigüedad y codificación inconsistente.\n",
        "\n",
        "Se generaron dos versiones del dataset:\n",
        "- Una que omite `CARGO` y `CENTRO_COSTO`, por tratarse de campos altamente heterogéneos que introducen dispersión semántica difícil de codificar.\n",
        "- Otra que los conserva, permitiendo evaluar su inclusión posterior como variables categóricas, si se desea estudiar su aporte predictivo mediante codificación controlada.\n",
        "\n",
        "Esta estrategia balancea limpieza estructural con flexibilidad analítica, dejando abierta la posibilidad de incorporar variables descartadas en etapas posteriores si su valor informativo lo justifica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R4E5AB5bI241",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4E5AB5bI241",
        "outputId": "c9c8156c-cec5-44e6-d20c-fa5afb5bf794"
      },
      "outputs": [],
      "source": [
        "# Columnas a eliminar por criterios de no pertinencia directa en modelado\n",
        "columnas_excluir = ['FECHA INGRESO', 'FECHA RETIRO', 'FECHA NACIMIENTO',\n",
        "                    'REGIONAL - BSC', 'SUELDO','AÑO_REFERENCIA']\n",
        "\n",
        "# Dataset sin columnas excluidas, sin CARGO ni CENTRO_COSTO\n",
        "df_sin_cargo_centro = df_personal.drop(columns=columnas_excluir + ['CARGO', 'CENTRO_COSTO'])\n",
        "df_sin_cargo_centro.info()\n",
        "\n",
        "# Dataset sin columnas excluidas, pero manteniendo CARGO y CENTRO_COSTO\n",
        "df_con_cargo_centro = df_personal.drop(columns=columnas_excluir)\n",
        "df_con_cargo_centro.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ldSvr_qTJAr1",
      "metadata": {
        "id": "ldSvr_qTJAr1"
      },
      "source": [
        "### **3.1.7. Preprocesamiento de los Datos**\n",
        "---\n",
        "\n",
        "Con el objetivo de preparar el conjunto de datos para la construcción de modelos predictivos, se realizó un proceso sistemático de preprocesamiento orientado a tres tareas principales: clasificación binaria del estado laboral (`ACTIVO`), categorización de la permanencia (`PERMANENCIA_RANGO`) y regresión sobre la duración exacta de la permanencia (`PERMANENCIA_DIAS`).\n",
        "\n",
        "Para ello, se generaron seis subconjuntos de datos divididos entre dos enfoques:\n",
        "- Uno que incluye las variables `CARGO` y `CENTRO_COSTO`, asumiendo que pueden aportar información predictiva si son correctamente codificadas.\n",
        "- Otro que excluye estas variables, priorizando homogeneidad y robustez frente a ambigüedades semánticas.\n",
        "\n",
        "Las variables categóricas fueron procesadas mediante **One-Hot Encoding**, lo que permite que el modelo trate adecuadamente categorías no ordinales sin introducir jerarquías arbitrarias. Las variables numéricas fueron estandarizadas utilizando **StandardScaler**, centrando en cero y escalando por desviación estándar, lo cual favorece algoritmos sensibles a la escala como redes neuronales o modelos lineales. Esta decisión se justificó por la presencia de colas moderadamente largas en variables como `SUELDO_EN_SM` y `EDAD`, donde un escalado basado en máximos podría haber distorsionado el aprendizaje.\n",
        "\n",
        "La variable objetivo (`y`) fue tratada según su naturaleza:\n",
        "- En el caso binario (`ACTIVO`), se codificó como 1 para \"Sí\" y 0 para \"No\".\n",
        "- Para la categorización de permanencia, se mantuvo como variable categórica con etiquetas ordinales.\n",
        "- Para la regresión, se utilizó directamente el número de días de permanencia (`PERMANENCIA_DIAS`) sin transformación adicional.\n",
        "\n",
        "Este preprocesamiento garantiza que cada modelo reciba datos estructurados, coherentes y escalados de forma apropiada, sentando las bases para una fase de entrenamiento robusta y reproducible.\n",
        "\n",
        "Nota adicional: A través de los resultados que se verán mas adelante se preparan los datos para categorización en versión binaria dependiendo si la salida es temprana o no (90 días).\n",
        "\n",
        "Nota adicional 2: Debido al desbalanceo de clases se utiliza SMOTE para agregar hacer sobrebalanceo sobre la variable objetivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_iaGIyvfJQVA",
      "metadata": {
        "id": "_iaGIyvfJQVA"
      },
      "outputs": [],
      "source": [
        "# Primer dataset: CON CARGO Y CENTRO_COSTO\n",
        "df1 = df_con_cargo_centro.copy()\n",
        "\n",
        "# Segundo dataset: SIN CARGO NI CENTRO_COSTO\n",
        "df2 = df_sin_cargo_centro.copy()\n",
        "\n",
        "# -----------------------------\n",
        "# Modelos con y = ACTIVO (binaria)\n",
        "# -----------------------------\n",
        "X1_activo = df1.drop(columns=['ACTIVO', 'PERMANENCIA_DIAS', 'PERMANENCIA_RANGO'])\n",
        "y1_activo = df1['ACTIVO']\n",
        "\n",
        "\n",
        "X2_activo = df2.drop(columns=['ACTIVO', 'PERMANENCIA_DIAS', 'PERMANENCIA_RANGO'])\n",
        "y2_activo = df2['ACTIVO']\n",
        "\n",
        "# -----------------------------\n",
        "# Modelos con solo RETIRADOS\n",
        "# -----------------------------\n",
        "# Filtrar retirados\n",
        "df1_ret = df1[df1['ACTIVO'] == \"No\"].drop(columns=['ACTIVO'])\n",
        "df2_ret = df2[df2['ACTIVO'] == \"No\"].drop(columns=['ACTIVO'])\n",
        "\n",
        "# y = PERMANENCIA_RANGO (categórica)\n",
        "X1_rango = df1_ret.drop(columns=['PERMANENCIA_RANGO', 'PERMANENCIA_DIAS'])\n",
        "y1_rango = df1_ret['PERMANENCIA_RANGO']\n",
        "\n",
        "X2_rango = df2_ret.drop(columns=['PERMANENCIA_RANGO', 'PERMANENCIA_DIAS'])\n",
        "y2_rango = df2_ret['PERMANENCIA_RANGO']\n",
        "\n",
        "# y = PERMANENCIA_DIAS (regresión)\n",
        "X1_dias = df1_ret.drop(columns=['PERMANENCIA_RANGO', 'PERMANENCIA_DIAS'])\n",
        "y1_dias = df1_ret['PERMANENCIA_DIAS']\n",
        "\n",
        "X2_dias = df2_ret.drop(columns=['PERMANENCIA_RANGO', 'PERMANENCIA_DIAS'])\n",
        "y2_dias = df2_ret['PERMANENCIA_DIAS']\n",
        "\n",
        "# y =  PERMANENCIA_RANGO (binaria)\n",
        "X1_bin = df1_ret.drop(columns=['PERMANENCIA_RANGO', 'PERMANENCIA_DIAS'])\n",
        "y1_bin = df1_ret['PERMANENCIA_DIAS'].apply(lambda x: 0 if x > 90 else 1)\n",
        "\n",
        "X2_bin = df2_ret.drop(columns=['PERMANENCIA_RANGO', 'PERMANENCIA_DIAS'])\n",
        "y2_bin = df2_ret['PERMANENCIA_DIAS'].apply(lambda x: 0 if x > 90 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tRqOa5yhnfh-",
      "metadata": {
        "id": "tRqOa5yhnfh-"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Función para codificar 'ACTIVO'\n",
        "def codificar_binaria(y_txt):\n",
        "    return y_txt.map({'Si': 1, 'No': 0}).values\n",
        "\n",
        "# Función de preprocesamiento\n",
        "def preprocesar(df):\n",
        "    categoric_df = df.select_dtypes(include=['object', 'category'])\n",
        "    numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "    onehot = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    tf = ColumnTransformer(transformers=[\n",
        "        ('onehot', onehot, categoric_df.columns),\n",
        "        ('scaler', scaler, numeric_df.columns)\n",
        "    ], remainder='drop')\n",
        "\n",
        "    X = tf.fit_transform(df)\n",
        "    return X, tf\n",
        "\n",
        "# Equilibrador de clases\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# Clasificación binaria (ACTIVO)\n",
        "X1_act, tf_X1_act = preprocesar(X1_activo)\n",
        "y1_act = codificar_binaria(y1_activo)\n",
        "X1_act, y1_act = smote.fit_resample(X1_act, y1_act)\n",
        "\n",
        "\n",
        "X2_act, tf_X2_act = preprocesar(X2_activo)\n",
        "y2_act = codificar_binaria(y2_activo)\n",
        "X2_act, y2_act = smote.fit_resample(X2_act, y2_act)\n",
        "\n",
        "# Categorización (PERMANENCIA_RANGO)\n",
        "X1_rng, tf_X1_rng = preprocesar(X1_rango)\n",
        "y1_rng = y1_rango.values\n",
        "X1_rng, y1_rng = smote.fit_resample(X1_rng, y1_rng)\n",
        "\n",
        "X2_rng, tf_X2_rng = preprocesar(X2_rango)\n",
        "y2_rng = y2_rango.values\n",
        "X2_rng, y2_rng = smote.fit_resample(X2_rng, y2_rng)\n",
        "\n",
        "# Regresión (PERMANENCIA_DIAS)\n",
        "X1_days, tf_X1_days = preprocesar(X1_dias)\n",
        "y1_days = y1_dias.values\n",
        "\n",
        "X2_days, tf_X2_days = preprocesar(X2_dias)\n",
        "y2_days = y2_dias.values\n",
        "\n",
        "# Clasificación binaria (PERMANENCIA_RANGO)\n",
        "X1_bin_rng, tf_X1_bin_rng = preprocesar(X1_bin)\n",
        "y1_rng_bin = y1_bin\n",
        "X1_bin_rng, y1_rng_bin = smote.fit_resample(X1_bin_rng, y1_rng_bin)\n",
        "\n",
        "X2_bin_rng, tf_X2_bin_rng = preprocesar(X2_bin)\n",
        "y2_rng_bin = y2_bin\n",
        "X2_bin_rng, y2_rng_bin = smote.fit_resample(X2_bin_rng, y2_rng_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d2e6e40",
      "metadata": {
        "id": "3d2e6e40"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Clasificación binaria - particiones de test estratificado\n",
        "X1_act_train, X1_act_test, y1_act_train, y1_act_test = train_test_split(X1_act, y1_act, test_size=0.3, stratify=y1_act, random_state=42)\n",
        "X2_act_train, X2_act_test, y2_act_train, y2_act_test = train_test_split(X2_act, y2_act, test_size=0.3, stratify=y2_act, random_state=42)\n",
        "# Categoraización - particiones de test estratificado\n",
        "X1_rng_train, X1_rng_test, y1_rng_train, y1_rng_test = train_test_split(X1_rng, y1_rng, test_size=0.3, stratify=y1_rng, random_state=42)\n",
        "X2_rng_train, X2_rng_test, y2_rng_train, y2_rng_test = train_test_split(X2_rng, y2_rng, test_size=0.3, stratify=y2_rng, random_state=42)\n",
        "# Regresión - particiones de test\n",
        "X1_days_train, X1_days_test, y1_days_train, y1_days_test = train_test_split(X1_days, y1_days, test_size=0.3, random_state=42)\n",
        "X2_days_train, X2_days_test, y2_days_train, y2_days_test = train_test_split(X2_days, y2_days, test_size=0.3, random_state=42)\n",
        "# Clasificación binaria - particiones de test estratificado\n",
        "X1_bin_rng_train, X1_bin_rng_test, y1_bin_rng_train, y1_bin_rng_test = train_test_split(X1_bin_rng, y1_rng_bin, test_size=0.3, stratify=y1_rng_bin, random_state=42)\n",
        "X2_bin_rng_train, X2_bin_rng_test, y2_bin_rng_train, y2_bin_rng_test = train_test_split(X2_bin_rng, y2_rng_bin, test_size=0.3, stratify=y2_rng_bin, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db98c1e5",
      "metadata": {
        "id": "db98c1e5"
      },
      "source": [
        "# **4. Modelamiento y Validación**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fef6dbc",
      "metadata": {
        "id": "3fef6dbc"
      },
      "source": [
        "## **4.1. Selección y diseño de modelos**\n",
        "---\n",
        "\n",
        "En este trabajo se planteó la construcción de un sistema de predicción sobre la permanencia laboral del personal, abordado desde tres enfoques analíticos distintos:\n",
        "\n",
        "- **Clasificación binaria:** Determinar si una persona está activa o retirada.\n",
        "- **Regresión:** Predecir la cantidad de días que un empleado permanece en la organización.\n",
        "- **Categorización:** Agrupar la permanencia en rangos (0–90, 91–180, 181–365 y >365 días).\n",
        "\n",
        "Para cada uno de estos tres problemas se seleccionaron **tres modelos supervisados clásicos**, representativos de enfoques distintos:\n",
        "\n",
        "- **KNN (K-Nearest Neighbors):** modelo basado en la similitud entre observaciones.\n",
        "- **SVC/SVR (Support Vector Machines):** modelo robusto para clasificación y regresión no lineal.\n",
        "- **Árboles de Decisión:** modelo interpretable que permite capturar relaciones jerárquicas y no lineales.\n",
        "\n",
        "Cada uno de estos modelos fue evaluado con **dos configuraciones de datos**:\n",
        "\n",
        "- `X1`: con inclusión de las variables **CARGO** y **CENTRO DE COSTO**.\n",
        "- `X2`: sin estas variables, para evaluar su influencia en la capacidad predictiva.\n",
        "\n",
        "### Enfoque del Ejercicio\n",
        "\n",
        "La elección de estos modelos no responde a una búsqueda de desempeño óptimo desde el inicio, sino a una lógica de **exploración y aprendizaje**, enmarcada dentro del proceso de **experimentación controlada**. Se trata de identificar:\n",
        "\n",
        "- Qué tan útil es la información actual para tareas predictivas.\n",
        "- Qué configuraciones de variables impactan más el resultado.\n",
        "- Cuáles son las limitaciones del dataset y el modelo actual.\n",
        "- Qué caminos podrían explorarse en futuras iteraciones del proyecto.\n",
        "\n",
        "En este sentido, **los resultados obtenidos no deben ser tomados como productos finales**, sino como un **primer acercamiento práctico** para construir una base conceptual y técnica sobre la cual iterar y mejorar.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69IgxnSjbO0l",
      "metadata": {
        "id": "69IgxnSjbO0l"
      },
      "source": [
        "## **4.2. Clasificación Binaria: Identificación de Personas Activas o Retiradas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MI6VjAgLr_q-",
      "metadata": {
        "id": "MI6VjAgLr_q-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, validation_curve, learning_curve, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_curve, auc\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "def plot_validation_curve(model, X, y, param_name, param_range, scoring='f1'):\n",
        "    train_scores, val_scores = validation_curve(\n",
        "        model, X, y,\n",
        "        param_name=param_name,\n",
        "        param_range=param_range,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    plt.figure()\n",
        "    plt.plot(param_range, train_scores.mean(axis=1), label=\"Train\")\n",
        "    plt.plot(param_range, val_scores.mean(axis=1), label=\"Validation\")\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel(scoring)\n",
        "    plt.title(f'Curva de Validación - {model.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_learning_curve(model, X, y, scoring='f1'):\n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        model, X, y,\n",
        "        train_sizes=np.linspace(0.1, 1.0, 8),\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    plt.figure()\n",
        "    plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Train\")\n",
        "    plt.plot(train_sizes, val_scores.mean(axis=1), label=\"Validation\")\n",
        "    plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "    plt.ylabel(scoring)\n",
        "    plt.title(f'Curva de Aprendizaje - {model.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc_curve(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Genera la curva ROC para un modelo binario.\n",
        "\n",
        "    Parámetros:\n",
        "    - model: modelo ya entrenado\n",
        "    - X_test: conjunto de datos de prueba\n",
        "    - y_test: etiquetas verdaderas del conjunto de prueba\n",
        "    \"\"\"\n",
        "    # Obtener probabilidades de clase positiva\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_scores = model.predict_proba(X_test)[:, 1]\n",
        "    elif hasattr(model, \"decision_function\"):\n",
        "        y_scores = model.decision_function(X_test)\n",
        "    else:\n",
        "        raise ValueError(\"El modelo no soporta predict_proba ni decision_function\")\n",
        "\n",
        "    # Calcular la curva ROC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Graficar la curva ROC\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
        "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
        "    plt.title(f'Curva ROC - {model.__class__.__name__}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_feature_importance(model, transformer, top_n=20, title=\"Importancia de características\"):\n",
        "    \"\"\"\n",
        "    Grafica las importancias de las características de un modelo basado en árboles\n",
        "    usando los nombres reales extraídos del transformador de columnas.\n",
        "\n",
        "    Parámetros:\n",
        "    - model: Modelo entrenado con feature_importances_ (RandomForest, GradientBoosting, etc.).\n",
        "    - transformer: ColumnTransformer usado en el preprocesamiento (debe tener 'onehot' y 'scaler').\n",
        "    - top_n: Número de características más importantes a visualizar.\n",
        "    - title: Título del gráfico.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extraer nombres codificados de OneHotEncoder\n",
        "    onehot = transformer.named_transformers_['onehot']\n",
        "    onehot_features = onehot.get_feature_names_out(transformer.transformers_[0][2])  # columnas categóricas\n",
        "\n",
        "    # Nombres de las columnas numéricas\n",
        "    numeric_features = transformer.transformers_[1][2]\n",
        "\n",
        "    # Unir los nombres\n",
        "    all_features = np.concatenate([onehot_features, numeric_features])\n",
        "\n",
        "    # Obtener importancias\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    # Validación\n",
        "    if len(importances) != len(all_features):\n",
        "        print(f\"⚠️ Error: {len(importances)} importancias vs {len(all_features)} features.\")\n",
        "        return\n",
        "\n",
        "    # Crear Series para graficar\n",
        "    feature_importances = pd.Series(importances, index=all_features)\n",
        "\n",
        "    # Visualizar\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    feature_importances.nlargest(top_n).plot(kind='barh')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Importancia\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VQz3yfcMIP4y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VQz3yfcMIP4y",
        "outputId": "fccc1e4b-caca-40ba-fa2e-1c2ce0a383cc"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 1: KNN -----------\n",
        "print(\"\\n=== KNN X1 ===\")\n",
        "knn = KNeighborsClassifier()\n",
        "knn_params = {'n_neighbors': [1,2,3,4,5]}\n",
        "grid_knn = GridSearchCV(knn, knn_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_knn.fit(X1_act_train, y1_act_train)\n",
        "\n",
        "print(\"Mejor K:\", grid_knn.best_params_)\n",
        "y_pred = grid_knn.predict(X1_act_test)\n",
        "print(\"F1:\", f1_score(y1_act_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y1_act_test, y_pred))\n",
        "print(classification_report(y1_act_test, y_pred))\n",
        "\n",
        "plot_validation_curve(knn, X1_act_train, y1_act_train, 'n_neighbors', [1,2,3,4,5])\n",
        "plot_learning_curve(grid_knn.best_estimator_, X1_act_train, y1_act_train)\n",
        "plot_roc_curve(grid_knn.best_estimator_, X1_act_test, y1_act_test)\n",
        "\n",
        "print(\"\\n=== KNN X2 ===\")\n",
        "grid_knn2 = GridSearchCV(knn, knn_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_knn2.fit(X2_act_train, y2_act_train)\n",
        "\n",
        "print(\"Mejor K:\", grid_knn2.best_params_)\n",
        "y_pred = grid_knn2.predict(X2_act_test)\n",
        "print(\"F1:\", f1_score(y2_act_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y2_act_test, y_pred))\n",
        "print(classification_report(y2_act_test, y_pred))\n",
        "\n",
        "plot_validation_curve(knn, X2_act_train, y2_act_train, 'n_neighbors', [1,2,3,4,5])\n",
        "plot_learning_curve(grid_knn2.best_estimator_, X2_act_train, y2_act_train)\n",
        "plot_roc_curve(grid_knn2.best_estimator_, X2_act_test, y2_act_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fOE1XWRuIQQw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "fOE1XWRuIQQw",
        "outputId": "1ff01730-bbcb-4c43-d47d-085397174711"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 2: SVC -----------\n",
        "print(\"\\n=== SVC X1 ===\")\n",
        "svc = SVC(probability=True, random_state=42)\n",
        "svc_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid_svc = GridSearchCV(svc, svc_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_svc.fit(X1_act_train, y1_act_train)\n",
        "\n",
        "print(\"Mejores params SVC:\", grid_svc.best_params_)\n",
        "y_pred = grid_svc.predict(X1_act_test)\n",
        "print(\"F1:\", f1_score(y1_act_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y1_act_test, y_pred))\n",
        "print(classification_report(y1_act_test, y_pred))\n",
        "\n",
        "plot_validation_curve(svc, X1_act_train, y1_act_train, 'C', [0.1, 1, 10])\n",
        "plot_learning_curve(grid_svc.best_estimator_, X1_act_train, y1_act_train)\n",
        "plot_roc_curve(grid_svc.best_estimator_, X1_act_test, y1_act_test)\n",
        "\n",
        "print(\"\\n=== SVC X2 ===\")\n",
        "grid_svc2 = GridSearchCV(svc, svc_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_svc2.fit(X2_act_train, y2_act_train)\n",
        "\n",
        "print(\"Mejores params SVC:\", grid_svc2.best_params_)\n",
        "y_pred = grid_svc2.predict(X2_act_test)\n",
        "print(\"F1:\", f1_score(y2_act_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y2_act_test, y_pred))\n",
        "print(classification_report(y2_act_test, y_pred))\n",
        "\n",
        "plot_validation_curve(svc, X2_act_train, y2_act_train, 'C', [0.1, 1, 10])\n",
        "plot_learning_curve(grid_svc2.best_estimator_, X2_act_train, y2_act_train)\n",
        "plot_roc_curve(grid_svc2.best_estimator_, X2_act_test, y2_act_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UQ9uqwZhIRYy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UQ9uqwZhIRYy",
        "outputId": "76f8b976-c4e2-4813-ac14-83fc4102a156"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 3: Árbol de decisión -----------\n",
        "print(\"\\n=== Decision Tree X1 ===\")\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree_params = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5]}\n",
        "grid_tree = GridSearchCV(tree, tree_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_tree.fit(X1_act_train, y1_act_train)\n",
        "\n",
        "print(\"Mejores params Árbol:\", grid_tree.best_params_)\n",
        "y_pred = grid_tree.predict(X1_act_test)\n",
        "print(\"F1:\", f1_score(y1_act_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y1_act_test, y_pred))\n",
        "print(classification_report(y1_act_test, y_pred))\n",
        "\n",
        "plot_validation_curve(tree, X1_act_train, y1_act_train, 'max_depth', [3, 5, 10, None])\n",
        "plot_learning_curve(grid_tree.best_estimator_, X1_act_train, y1_act_train)\n",
        "plot_roc_curve(grid_tree.best_estimator_, X1_act_test, y1_act_test)\n",
        "plot_feature_importance(grid_tree.best_estimator_, tf_X1_act)\n",
        "\n",
        "print(\"\\n=== Decision Tree X2 ===\")\n",
        "grid_tree = GridSearchCV(tree, tree_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_tree.fit(X2_act_train, y2_act_train)\n",
        "\n",
        "print(\"Mejores params Árbol:\", grid_tree.best_params_)\n",
        "y_pred = grid_tree.predict(X2_act_test)\n",
        "print(\"F1:\", f1_score(y2_act_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y2_act_test, y_pred))\n",
        "print(classification_report(y2_act_test, y_pred))\n",
        "\n",
        "plot_validation_curve(tree, X2_act_train, y2_act_train, 'max_depth', [3, 5, 10, None])\n",
        "plot_learning_curve(grid_tree.best_estimator_, X2_act_train, y2_act_train)\n",
        "plot_roc_curve(grid_tree.best_estimator_, X2_act_test, y2_act_test)\n",
        "plot_feature_importance(grid_tree.best_estimator_, tf_X2_act)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fX8cIS421kc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fX8cIS421kc1",
        "outputId": "e430f465-965c-4c0c-fcfb-282779c58342"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ----------- MODELO COMPLEMENTARIO 1: Random Forest -----------\n",
        "print(\"\\n=== Random Forest X1 ===\")\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_params = {'n_estimators': [50, 100, 150]}\n",
        "grid_rf = GridSearchCV(rf, rf_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_rf.fit(X1_act_train, y1_act_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_rf.best_params_)\n",
        "y_pred_rf = grid_rf.predict(X1_act_test)\n",
        "print(\"F1:\", f1_score(y1_act_test, y_pred_rf))\n",
        "print(\"Accuracy:\", accuracy_score(y1_act_test, y_pred_rf))\n",
        "print(classification_report(y1_act_test, y_pred_rf))\n",
        "\n",
        "plot_validation_curve(rf, X1_act_train, y1_act_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_rf.best_estimator_, X1_act_train, y1_act_train)\n",
        "plot_roc_curve(grid_rf.best_estimator_, X1_act_test, y1_act_test)\n",
        "plot_feature_importance(grid_rf.best_estimator_, tf_X1_act)\n",
        "\n",
        "print(\"\\n=== Random Forest X2 ===\")\n",
        "grid_rf2 = GridSearchCV(rf, rf_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_rf2.fit(X2_act_train, y2_act_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_rf2.best_params_)\n",
        "y_pred_rf2 = grid_rf2.predict(X2_act_test)\n",
        "print(\"F1:\", f1_score(y2_act_test, y_pred_rf2))\n",
        "print(\"Accuracy:\", accuracy_score(y2_act_test, y_pred_rf2))\n",
        "print(classification_report(y2_act_test, y_pred_rf2))\n",
        "\n",
        "plot_validation_curve(rf, X2_act_train, y2_act_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_rf2.best_estimator_, X2_act_train, y2_act_train)\n",
        "plot_roc_curve(grid_rf2.best_estimator_, X2_act_test, y2_act_test)\n",
        "plot_feature_importance(grid_rf2.best_estimator_, tf_X2_act)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2mQfp_sd2QIT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2mQfp_sd2QIT",
        "outputId": "81893122-ba71-44a3-f25a-2ca0524996fd"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ----------- MODELO COMPLEMENTARIO 2: XGBoost -----------\n",
        "\n",
        "print(\"\\n=== XGBoost X1 ===\")\n",
        "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.05, 0.1, 0.2]}\n",
        "grid_xgb = GridSearchCV(xgb, xgb_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_xgb.fit(X1_act_train, y1_act_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_xgb.best_params_)\n",
        "y_pred_xgb = grid_xgb.predict(X1_act_test)\n",
        "print(\"F1:\", f1_score(y1_act_test, y_pred_xgb))\n",
        "print(\"Accuracy:\", accuracy_score(y1_act_test, y_pred_xgb))\n",
        "print(classification_report(y1_act_test, y_pred_xgb))\n",
        "\n",
        "plot_validation_curve(xgb, X1_act_train, y1_act_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_xgb.best_estimator_, X1_act_train, y1_act_train)\n",
        "plot_roc_curve(grid_xgb.best_estimator_, X1_act_test, y1_act_test)\n",
        "plot_feature_importance(grid_xgb.best_estimator_, tf_X1_act)\n",
        "\n",
        "# ----------- XGBoost X2 -----------\n",
        "print(\"\\n=== XGBoost X2 ===\")\n",
        "grid_xgb2 = GridSearchCV(xgb, xgb_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_xgb2.fit(X2_act_train, y2_act_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_xgb2.best_params_)\n",
        "y_pred_xgb2 = grid_xgb2.predict(X2_act_test)\n",
        "print(\"F1:\", f1_score(y2_act_test, y_pred_xgb2))\n",
        "print(\"Accuracy:\", accuracy_score(y2_act_test, y_pred_xgb2))\n",
        "print(classification_report(y2_act_test, y_pred_xgb2))\n",
        "\n",
        "plot_validation_curve(xgb, X2_act_train, y2_act_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_xgb2.best_estimator_, X2_act_train, y2_act_train)\n",
        "plot_roc_curve(grid_xgb2.best_estimator_, X2_act_test, y2_act_test)\n",
        "plot_feature_importance(grid_xgb2.best_estimator_, tf_X2_act)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S39Zs10TLTZq",
      "metadata": {
        "id": "S39Zs10TLTZq"
      },
      "source": [
        "### 4.2.1. Balance General de Resultados\n",
        "\n",
        "Se evaluaron cinco algoritmos de clasificación binaria para predecir la condición laboral (activo o retirado), a saber: K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), Árbol de Decisión, Random Forest y XGBoost. Cada modelo fue entrenado y validado con dos subconjuntos de características (X1 y X2), y se utilizaron métricas como F1-score, accuracy y AUC-ROC, así como curvas de validación, aprendizaje y de importancia de características.\n",
        "\n",
        "A continuación se presenta un resumen comparativo de los resultados obtenidos para cada modelo:\n",
        "\n",
        "| Modelo           | Conjunto | F1-score | Accuracy | AUC-ROC | Observación Clave                  |\n",
        "|------------------|----------|----------|----------|---------|------------------------------------|\n",
        "| **KNN**          | X1       | 0.83     | 0.82     | 0.82    | Alto sobreajuste, buena sensibilidad |\n",
        "|                  | X2       | 0.77     | 0.76     | 0.76    | Menor generalización               |\n",
        "| **SVC**          | X1       | 0.83     | 0.82     | 0.91    | Generalización sólida, buen AUC    |\n",
        "|                  | X2       | 0.73     | 0.72     | 0.79    | Menor rendimiento con X2           |\n",
        "| **Árbol de Decisión** | X1   | 0.87     | 0.87     | 0.87    | Buen equilibrio interpretabilidad-rendimiento |\n",
        "|                  | X2       | 0.82     | 0.82     | 0.83    | Correcto pero no sobresaliente     |\n",
        "| **Random Forest**| X1       | **0.90** | **0.90** | 0.96    | Excelente desempeño y AUC          |\n",
        "|                  | X2       | 0.84     | 0.84     | 0.91    | Buena generalización               |\n",
        "| **XGBoost**      | X1       | 0.89     | 0.89     | **0.97**| Mejor curva ROC, gran generalización |\n",
        "|                  | X2       | 0.87     | 0.87     | 0.94    | Modelo robusto incluso con menos features |\n",
        "\n",
        "### 4.2.2. Modelo Seleccionado\n",
        "\n",
        "Tras el análisis exhaustivo de métricas cuantitativas y gráficas, el modelo seleccionado es:\n",
        "\n",
        "> 🎯 **XGBoost con el conjunto de variables X1**\n",
        "\n",
        "Este modelo obtuvo el segundo mejor F1-score (0.89), una accuracy elevada (0.89), y el mayor valor de AUC-ROC (0.97), indicando una excelente capacidad de discriminación entre clases. Asimismo, sus curvas de aprendizaje muestran una mejora sostenida y baja varianza en validación, lo cual sugiere una alta capacidad de generalización sin caer en sobreajuste extremo.\n",
        "\n",
        "Aunque Random Forest tuvo un rendimiento similar y podría considerarse igualmente robusto, XGBoost demostró una mayor eficiencia en la asignación de importancia a variables clave y una respuesta más estable frente a variaciones de datos.\n",
        "\n",
        "### 4.2.3. Aplicabilidad Real del Modelo\n",
        "\n",
        "Este modelo puede ser implementado como herramienta de apoyo para la gestión de talento humano, específicamente en:\n",
        "\n",
        "- **Detección temprana de riesgo de salida laboral**.\n",
        "- **Priorización de intervenciones (formación, entrevistas, reubicación)** para perfiles críticos.\n",
        "- **Análisis estratégico de procesos organizacionales** en relación con la retención de personal.\n",
        "\n",
        "Además, gracias a su alta precisión y capacidad predictiva, este modelo se perfila como un componente clave en un sistema de **People Analytics**, pudiendo integrarse con dashboards operativos, reportes automatizados o incluso desencadenar flujos de trabajo en plataformas de RRHH.\n",
        "\n",
        "Se recomienda complementar su implementación con herramientas de explicabilidad (como SHAP o LIME) para garantizar transparencia y confianza en la toma de decisiones.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.2.4 Limitaciones y Recomendaciones Futuras\n",
        "\n",
        "#### Limitaciones del Estudio\n",
        "\n",
        "- **Representatividad de los datos**: La calidad del modelo está condicionada por la representatividad del conjunto de entrenamiento. Si los datos históricos no capturan adecuadamente los patrones de salida laboral (por ejemplo, cambios estructurales recientes en la organización), el modelo puede perder validez predictiva.\n",
        "  \n",
        "- **Variables latentes no incluidas**: Factores como clima laboral, liderazgo, motivaciones personales o conflictos internos no fueron contemplados por limitaciones en la base de datos, lo cual reduce la profundidad explicativa del modelo.\n",
        "\n",
        "- **Posible sesgo en variables categóricas**: Algunas variables como el centro de costo o el cargo podrían estar correlacionadas con decisiones históricas sesgadas. Sin análisis de fairness o auditoría algorítmica, esto podría perpetuar patrones indeseados.\n",
        "\n",
        "- **Sensibilidad a cambios organizacionales**: En entornos dinámicos, los modelos pierden precisión con el tiempo si no se reentrenan periódicamente. La estabilidad del modelo a largo plazo debe ser monitoreada.\n",
        "\n",
        "#### Recomendaciones para el Futuro\n",
        "\n",
        "1. **Ampliar la base de datos** incluyendo variables cualitativas (ej. resultados de encuestas internas, motivaciones personales) y nuevas dimensiones temporales que permitan analizar evolución de patrones de retención.\n",
        "\n",
        "2. **Implementar monitoreo en producción** del modelo mediante dashboards que rastreen métricas como F1-score, drift de variables y tasas de error para cada subgrupo poblacional.\n",
        "\n",
        "3. **Aplicar técnicas de explicabilidad** (ej. SHAP, LIME) que permitan comprender cómo y por qué se toman decisiones a nivel individual, promoviendo un uso ético y comprensible en recursos humanos.\n",
        "\n",
        "4. **Explorar enfoques multicapa** como modelos híbridos que combinen predicciones cuantitativas con reglas heurísticas o entrevistas de retención.\n",
        "\n",
        "5. **Evaluar impacto de decisiones automatizadas**: Antes de usar el modelo en decisiones críticas (como cancelación de renovación de contrato o asignación de beneficios), es esencial evaluar el impacto organizacional y ético.\n",
        "\n",
        "---\n",
        "\n",
        "Con esta sección final, se cierra el análisis con un enfoque crítico que no solo reconoce los aciertos del modelo, sino que también propone un camino evolutivo para su uso responsable y efectivo en contextos organizacionales reales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iL4r0QU-bVgk",
      "metadata": {
        "id": "iL4r0QU-bVgk"
      },
      "source": [
        "## **4.3. Regresión: Predicción de la Permanencia en Días**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KoVJts2sOS7p",
      "metadata": {
        "id": "KoVJts2sOS7p"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "cv = 5  # k-fold cross-validation\n",
        "\n",
        "def plot_validation_curveR(model, X, y, param_name, param_range):\n",
        "    train_scores, val_scores = validation_curve(\n",
        "        model, X, y,\n",
        "        param_name=param_name,\n",
        "        param_range=param_range,\n",
        "        cv=cv,\n",
        "        scoring='r2',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    plt.figure()\n",
        "    plt.plot(param_range, train_scores.mean(axis=1), label=\"Train\")\n",
        "    plt.plot(param_range, val_scores.mean(axis=1), label=\"Validation\")\n",
        "    plt.xlabel(param_name)\n",
        "    plt.ylabel(\"R2 Score\")\n",
        "    plt.title(f'Curva de Validación - {model.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_learning_curveR(model, X, y):\n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        model, X, y,\n",
        "        train_sizes=np.linspace(0.1, 1.0, 8),\n",
        "        cv=cv,\n",
        "        scoring='r2',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    plt.figure()\n",
        "    plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Train\")\n",
        "    plt.plot(train_sizes, val_scores.mean(axis=1), label=\"Validation\")\n",
        "    plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "    plt.ylabel(\"R2 Score\")\n",
        "    plt.title(f'Curva de Aprendizaje - {model.__class__.__name__}')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SBL2mgUeMyb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SBL2mgUeMyb5",
        "outputId": "b9fcbe6e-28ee-46e3-d42a-958ddcec3a5b"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 1: KNN -----------\n",
        "print(\"\\n=== KNN X1 ===\")\n",
        "knn = KNeighborsRegressor()\n",
        "knn_params = {'n_neighbors': [1,2,3,4,5,6,7,8]}\n",
        "grid_knn = GridSearchCV(knn, knn_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_knn.fit(X1_days_train, y1_days_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_knn.best_params_)\n",
        "y_pred = grid_knn.predict(X1_days_test)\n",
        "print(\"R2:\", r2_score(y1_days_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y1_days_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y1_days_test, y_pred))\n",
        "\n",
        "plot_validation_curveR(knn, X1_days_train, y1_days_train, 'n_neighbors', [1,2,3,4,5,6,7,8])\n",
        "plot_learning_curveR(grid_knn.best_estimator_, X1_days_train, y1_days_train)\n",
        "\n",
        "print(\"\\n=== KNN X2 ===\")\n",
        "grid_knn2 = GridSearchCV(knn, knn_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_knn2.fit(X2_days_train, y2_days_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_knn2.best_params_)\n",
        "y_pred = grid_knn2.predict(X2_days_test)\n",
        "print(\"R2:\", r2_score(y2_days_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y2_days_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y2_days_test, y_pred))\n",
        "\n",
        "plot_validation_curveR(knn, X2_days_train, y2_days_train, 'n_neighbors', [1,2,3,4,5,6,7,8])\n",
        "plot_learning_curveR(grid_knn2.best_estimator_, X2_days_train, y2_days_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2FliCUBPTPXw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2FliCUBPTPXw",
        "outputId": "263c2a9b-531d-445c-81ce-6072211aefb8"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 2: SVR -----------\n",
        "\n",
        "print(\"\\n=== SVR X1 ===\")\n",
        "svr = SVR()\n",
        "svr_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid_svr = GridSearchCV(svr, svr_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_svr.fit(X1_days_train, y1_days_train)\n",
        "\n",
        "y_pred_svr_x1 = grid_svr.predict(X1_days_test)\n",
        "print(\"Mejores parámetros:\", grid_svr.best_params_)\n",
        "print(\"R2:\", r2_score(y1_days_test, y_pred_svr_x1))\n",
        "print(\"MAE:\", mean_absolute_error(y1_days_test, y_pred_svr_x1))\n",
        "print(\"MSE:\", mean_squared_error(y1_days_test, y_pred_svr_x1))\n",
        "\n",
        "plot_validation_curveR(SVR(), X1_days_train, y1_days_train, 'C', [0.1, 1, 10])\n",
        "plot_learning_curveR(grid_svr.best_estimator_, X1_days_train, y1_days_train)\n",
        "\n",
        "print(\"\\n=== SVR X2 ===\")\n",
        "grid_svr2 = GridSearchCV(svr, svr_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_svr2.fit(X2_days_train, y2_days_train)\n",
        "\n",
        "y_pred_svr_x2 = grid_svr2.predict(X2_days_test)\n",
        "print(\"Mejores parámetros:\", grid_svr2.best_params_)\n",
        "print(\"R2:\", r2_score(y2_days_test, y_pred_svr_x2))\n",
        "print(\"MAE:\", mean_absolute_error(y2_days_test, y_pred_svr_x2))\n",
        "print(\"MSE:\", mean_squared_error(y2_days_test, y_pred_svr_x2))\n",
        "\n",
        "plot_validation_curveR(SVR(), X2_days_train, y2_days_train, 'C', [0.1, 1, 10])\n",
        "plot_learning_curveR(grid_svr2.best_estimator_, X2_days_train, y2_days_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rer7DTGlQwFC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rer7DTGlQwFC",
        "outputId": "aeaceb13-ed2d-484f-d1cb-c2cfca903039"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 3: Decision Tree -----------\n",
        "\n",
        "print(\"\\n=== Decision Tree X1 ===\")\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_params = {'max_depth': [1, 3, 5, 10, None]}\n",
        "grid_dt = GridSearchCV(dt_reg, dt_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_dt.fit(X1_days_train, y1_days_train)\n",
        "\n",
        "y_pred_dt_x1 = grid_dt.predict(X1_days_test)\n",
        "print(\"Mejores parámetros:\", grid_dt.best_params_)\n",
        "print(\"R2:\", r2_score(y1_days_test, y_pred_dt_x1))\n",
        "print(\"MAE:\", mean_absolute_error(y1_days_test, y_pred_dt_x1))\n",
        "print(\"MSE:\", mean_squared_error(y1_days_test, y_pred_dt_x1))\n",
        "\n",
        "plot_validation_curveR(grid_dt.best_estimator_, X1_days_train, y1_days_train, 'max_depth', [1, 3, 5, 10, None])\n",
        "plot_learning_curveR(grid_dt.best_estimator_, X1_days_train, y1_days_train)\n",
        "plot_feature_importance(grid_dt.best_estimator_, tf_X1_days)\n",
        "\n",
        "print(\"\\n=== Decision Tree X2 ===\")\n",
        "grid_dt2 = GridSearchCV(dt_reg, dt_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_dt2.fit(X2_days_train, y2_days_train)\n",
        "\n",
        "y_pred_dt_x2 = grid_dt2.predict(X2_days_test)\n",
        "print(\"Mejores parámetros:\", grid_dt2.best_params_)\n",
        "print(\"R2:\", r2_score(y2_days_test, y_pred_dt_x2))\n",
        "print(\"MAE:\", mean_absolute_error(y2_days_test, y_pred_dt_x2))\n",
        "print(\"MSE:\", mean_squared_error(y2_days_test, y_pred_dt_x2))\n",
        "\n",
        "plot_validation_curveR(grid_dt2.best_estimator_, X2_days_train, y2_days_train, 'max_depth', [1, 3, 5, 10, None])\n",
        "plot_learning_curveR(grid_dt2.best_estimator_, X2_days_train, y2_days_train)\n",
        "plot_feature_importance(grid_dt2.best_estimator_, tf_X2_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U-2nkd073tut",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U-2nkd073tut",
        "outputId": "fed22a3a-3db8-4e87-ed1c-49c7006c2daf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# ----------- MODELO COMPLEMENTARIO 1: Random Forest Regressor -----------\n",
        "print(\"\\n=== Random Forest X1 ===\")\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf_params = {'n_estimators': [50, 100, 150]}\n",
        "grid_rf = GridSearchCV(rf, rf_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_rf.fit(X1_days_train, y1_days_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_rf.best_params_)\n",
        "y_pred_rf = grid_rf.predict(X1_days_test)\n",
        "print(\"R2:\", r2_score(y1_days_test, y_pred_rf))\n",
        "print(\"MAE:\", mean_absolute_error(y1_days_test, y_pred_rf))\n",
        "print(\"MSE:\", mean_squared_error(y1_days_test, y_pred_rf))\n",
        "\n",
        "plot_validation_curveR(rf, X1_days_train, y1_days_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curveR(grid_rf.best_estimator_, X1_days_train, y1_days_train)\n",
        "plot_feature_importance(grid_rf.best_estimator_, tf_X1_days)\n",
        "\n",
        "print(\"\\n=== Random Forest X2 ===\")\n",
        "grid_rf2 = GridSearchCV(rf, rf_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_rf2.fit(X2_days_train, y2_days_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_rf2.best_params_)\n",
        "y_pred_rf2 = grid_rf2.predict(X2_days_test)\n",
        "print(\"R2:\", r2_score(y2_days_test, y_pred_rf2))\n",
        "print(\"MAE:\", mean_absolute_error(y2_days_test, y_pred_rf2))\n",
        "print(\"MSE:\", mean_squared_error(y2_days_test, y_pred_rf2))\n",
        "\n",
        "plot_validation_curveR(rf, X2_days_train, y2_days_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curveR(grid_rf2.best_estimator_, X2_days_train, y2_days_train)\n",
        "plot_feature_importance(grid_rf2.best_estimator_, tf_X2_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hQ3HYFAM32ai",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hQ3HYFAM32ai",
        "outputId": "e56c7f95-5e6c-4d9e-e7d2-a89a33e5a63b"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "# ----------- MODELO COMPLEMENTARIO 2: XGBoost Regressor -----------\n",
        "\n",
        "print(\"\\n=== XGBoost X1 ===\")\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "xgb_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.05, 0.1, 0.2]}\n",
        "grid_xgb = GridSearchCV(xgb, xgb_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_xgb.fit(X1_days_train, y1_days_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_xgb.best_params_)\n",
        "y_pred_xgb = grid_xgb.predict(X1_days_test)\n",
        "print(\"R2:\", r2_score(y1_days_test, y_pred_xgb))\n",
        "print(\"MAE:\", mean_absolute_error(y1_days_test, y_pred_xgb))\n",
        "print(\"MSE:\", mean_squared_error(y1_days_test, y_pred_xgb))\n",
        "\n",
        "plot_validation_curveR(xgb, X1_days_train, y1_days_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curveR(grid_xgb.best_estimator_, X1_days_train, y1_days_train)\n",
        "plot_feature_importance(grid_xgb.best_estimator_, tf_X1_days)\n",
        "\n",
        "print(\"\\n=== XGBoost X2 ===\")\n",
        "grid_xgb2 = GridSearchCV(xgb, xgb_params, cv=cv, scoring='r2', n_jobs=-1)\n",
        "grid_xgb2.fit(X2_days_train, y2_days_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_xgb2.best_params_)\n",
        "y_pred_xgb2 = grid_xgb2.predict(X2_days_test)\n",
        "print(\"R2:\", r2_score(y2_days_test, y_pred_xgb2))\n",
        "print(\"MAE:\", mean_absolute_error(y2_days_test, y_pred_xgb2))\n",
        "print(\"MSE:\", mean_squared_error(y2_days_test, y_pred_xgb2))\n",
        "\n",
        "plot_validation_curveR(xgb, X2_days_train, y2_days_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curveR(grid_xgb2.best_estimator_, X2_days_train, y2_days_train)\n",
        "plot_feature_importance(grid_xgb2.best_estimator_, tf_X2_days)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3sF4bi-sUtSB",
      "metadata": {
        "id": "3sF4bi-sUtSB"
      },
      "source": [
        "### 4.3.1. Balance General de Resultados\n",
        "\n",
        "Se evaluaron cinco algoritmos de regresión para predecir el número de días que un empleado permanece en la empresa, a saber: K-Nearest Neighbors (KNN), Support Vector Regressor (SVR), Árbol de Decisión, Random Forest y XGBoost. Cada modelo fue entrenado y validado con dos subconjuntos de características (X1 y X2), y se utilizaron métricas como el coeficiente de determinación R², el error absoluto medio (MAE) y el error cuadrático medio (MSE). También se analizaron curvas de validación, aprendizaje e importancia de características.\n",
        "\n",
        "A continuación se presenta un resumen comparativo de los resultados obtenidos para cada modelo:\n",
        "\n",
        "| Modelo             | Conjunto | R²     | MAE   | MSE      | Observación Clave                              |\n",
        "|--------------------|----------|--------|--------|-----------|------------------------------------------------|\n",
        "| **KNN**            | X1       | 0.2132 | 386.4 | 382,413   | Modelo simple, sensible al ruido               |\n",
        "|                    | X2       | 0.1465 | 405.3 | 414,823   | Menor generalización con menos features        |\n",
        "| **SVR**            | X1       | 0.0360 | 381.4 | 468,553   | Desempeño bajo, incapaz de capturar relaciones |\n",
        "|                    | X2       | -0.0392| 397.7 | 505,112   | Peor rendimiento global                        |\n",
        "| **Árbol de Decisión** | X1    | 0.0669 | 443.7 | 453,512   | Modelo plano, sobreajuste al primer split      |\n",
        "|                    | X2       | 0.0669 | 443.7 | 453,512   | Igual rendimiento; sensible a outliers         |\n",
        "| **Random Forest**  | X1       | 0.2532 | 360.0 | 362,968   | Sobreajuste evidente, aunque mejora métricas   |\n",
        "|                    | X2       | 0.1641 | 392.2 | 406,278   | Mayor robustez que modelos simples             |\n",
        "| **XGBoost**        | X1       | **0.2931** | 372.7 | **343,563** | Mejor balance general, buen ajuste y estabilidad |\n",
        "|                    | X2       | 0.2058 | 389.9 | 386,010   | Fuerte rendimiento incluso con menos variables |\n",
        "\n",
        "---\n",
        "\n",
        "### 4.3.2. Modelo Seleccionado\n",
        "\n",
        "Tras el análisis exhaustivo de métricas cuantitativas y gráficas, el modelo seleccionado es:\n",
        "\n",
        ">  **XGBoost con el conjunto de variables X1**\n",
        "\n",
        "Este modelo alcanzó el **mayor R² (0.2931)**, el **menor MSE (343,563)** y un MAE competitivo (372.7), mostrando la mejor capacidad para explicar la variabilidad en la permanencia laboral. Aunque Random Forest obtuvo métricas cercanas, XGBoost demostró mayor estabilidad y eficiencia, con una distribución más equitativa en la importancia de variables y curvas de aprendizaje más progresivas.\n",
        "\n",
        "Cabe destacar que, aunque el valor de R² aún es bajo, es el único modelo que muestra un camino claro para mejorar mediante ingeniería de características y técnicas de regularización avanzada.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.3.3. Aplicabilidad Real del Modelo\n",
        "\n",
        "Este modelo puede ser implementado como componente estratégico dentro de iniciativas de gestión predictiva del talento humano, en particular para:\n",
        "\n",
        "- **Estimar la permanencia esperada** de nuevos empleados con base en su perfil inicial.\n",
        "- **Detectar riesgos de salida temprana**, informando políticas de seguimiento, mentoría o incentivos.\n",
        "- **Ajustar procesos de selección y asignación** con base en patrones de retención históricos.\n",
        "- **Optimizar decisiones contractuales** (por ejemplo, evitar ofrecer contratos largos a perfiles con baja permanencia esperada).\n",
        "\n",
        "Si bien el modelo no predice con precisión el número exacto de días, sí proporciona una **estimación útil para priorización y análisis estratégico**, especialmente en combinación con otros indicadores de desempeño.\n",
        "\n",
        "Se sugiere el uso complementario de **intervalos de predicción**, segmentaciones por percentiles o categorización del tiempo esperado de permanencia en niveles (bajo, medio, alto).\n",
        "\n",
        "---\n",
        "\n",
        "### 4.3.4. Limitaciones y Recomendaciones Futuras\n",
        "\n",
        "#### Limitaciones del Estudio\n",
        "\n",
        "- **Bajo poder explicativo de los modelos**: El mejor modelo (XGBoost) apenas logra un R² del 29.3%, indicando que la mayoría de la variabilidad del tiempo de permanencia no está capturada por las variables disponibles.\n",
        "\n",
        "- **Carencia de variables cualitativas o temporales**: No se incluyen variables como el clima laboral, motivos personales de salida, desempeño en el cargo o dinámica de equipo, que podrían explicar mejor la rotación.\n",
        "\n",
        "- **Sobreajuste sistemático**: Random Forest y XGBoost tienden a ajustar demasiado los datos de entrenamiento. Las curvas de aprendizaje y validación sugieren que la complejidad del modelo supera la capacidad informativa de los datos actuales.\n",
        "\n",
        "- **Errores grandes en la predicción**: Un MAE promedio de 372 días es significativo en el contexto empresarial, y puede generar incertidumbre si se usa como herramienta operativa.\n",
        "\n",
        "#### Recomendaciones para el Futuro\n",
        "\n",
        "1. **Incorporar variables temporales** como fechas de inicio, duración de etapas de selección o datos históricos de promociones, para capturar dinámicas internas más complejas.\n",
        "\n",
        "2. **Explorar nuevos enfoques de modelado**: En lugar de predecir un valor continuo exacto, puede ser más efectivo predecir una categoría ordinal (ej. salida temprana, media, tardía).\n",
        "\n",
        "3. **Aplicar técnicas de reducción de dimensionalidad** (ej. PCA o agrupamiento de cargos/centros de costo) para eliminar ruido y redundancia en variables categóricas.\n",
        "\n",
        "4. **Construir modelos explicables**: Implementar herramientas como SHAP o LIME para interpretar cómo cada variable afecta la predicción individual, lo cual es clave para confianza organizacional.\n",
        "\n",
        "5. **Aumentar el tamaño y calidad de los datos** mediante recolección sistemática de variables no consideradas actualmente, como encuestas de clima, entrevistas de salida o registros de desempeño.\n",
        "\n",
        "---\n",
        "\n",
        "Con este análisis se cierra la evaluación de modelos de regresión, destacando tanto el potencial como las limitaciones del enfoque predictivo en el ámbito de la retención laboral. El camino futuro requiere combinar **mejor data, mayor explicabilidad y técnicas robustas de modelado**, alineadas con el contexto organizacional.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZnIKwR4WbZBC",
      "metadata": {
        "id": "ZnIKwR4WbZBC"
      },
      "source": [
        "## **4.4. Categorización: Predicción del Rango de Permanencia**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M_596c4pVwWk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M_596c4pVwWk",
        "outputId": "16168b68-f5db-425f-8d67-1d83cadd632d"
      },
      "outputs": [],
      "source": [
        "# MODELO KNN - Categorización (X1_rng)\n",
        "print(\"\\n=== KNN RNG X1 ===\")\n",
        "knn_rng = KNeighborsClassifier()\n",
        "knn_rng_params = {'n_neighbors': [1, 2, 3, 4, 5]}\n",
        "grid_knn_rng = GridSearchCV(knn_rng, knn_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_knn_rng.fit(X1_rng_train, y1_rng_train)\n",
        "\n",
        "print(\"Mejor K:\", grid_knn_rng.best_params_)\n",
        "y_pred_knn_rng_x1 = grid_knn_rng.predict(X1_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y1_rng_test, y_pred_knn_rng_x1, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y1_rng_test, y_pred_knn_rng_x1))\n",
        "print(classification_report(y1_rng_test, y_pred_knn_rng_x1))\n",
        "\n",
        "plot_validation_curve(knn_rng, X1_rng_train, y1_rng_train, 'n_neighbors', [1, 2, 3, 4, 5],scoring='f1_macro')\n",
        "plot_learning_curve(grid_knn_rng.best_estimator_, X1_rng_train, y1_rng_train,scoring='f1_macro')\n",
        "\n",
        "# MODELO KNN - Categorización (X2_rng)\n",
        "print(\"\\n=== KNN RNG X2 ===\")\n",
        "grid_knn_rng2 = GridSearchCV(knn_rng, knn_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_knn_rng2.fit(X2_rng_train, y2_rng_train)\n",
        "\n",
        "print(\"Mejor K:\", grid_knn_rng2.best_params_)\n",
        "y_pred_knn_rng_x2 = grid_knn_rng2.predict(X2_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y2_rng_test, y_pred_knn_rng_x2, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y2_rng_test, y_pred_knn_rng_x2))\n",
        "print(classification_report(y2_rng_test, y_pred_knn_rng_x2))\n",
        "\n",
        "plot_validation_curve(knn_rng, X2_rng_train, y2_rng_train, 'n_neighbors', [1, 2, 3, 4, 5],scoring='f1_macro')\n",
        "plot_learning_curve(grid_knn_rng2.best_estimator_, X2_rng_train, y2_rng_train,scoring='f1_macro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vxQGODZeW2uw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vxQGODZeW2uw",
        "outputId": "cbb32faa-001a-457a-e014-f000b62f92a0"
      },
      "outputs": [],
      "source": [
        "# MODELO SVC - Categorización (X1_rng)\n",
        "print(\"\\n=== SVC RNG X1 ===\")\n",
        "svc_rng = SVC()\n",
        "svc_rng_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid_svc_rng = GridSearchCV(svc_rng, svc_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_svc_rng.fit(X1_rng_train, y1_rng_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_svc_rng.best_params_)\n",
        "y_pred_svc_rng_x1 = grid_svc_rng.predict(X1_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y1_rng_test, y_pred_svc_rng_x1, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y1_rng_test, y_pred_svc_rng_x1))\n",
        "print(classification_report(y1_rng_test, y_pred_svc_rng_x1))\n",
        "\n",
        "plot_validation_curve(grid_svc_rng.best_estimator_, X1_rng_train, y1_rng_train, 'C', [0.1, 1, 10], scoring='f1_macro')\n",
        "plot_learning_curve(grid_svc_rng.best_estimator_, X1_rng_train, y1_rng_train, scoring='f1_macro')\n",
        "\n",
        "# MODELO SVC - Categorización (X2_rng)\n",
        "print(\"\\n=== SVC RNG X2 ===\")\n",
        "grid_svc_rng2 = GridSearchCV(svc_rng, svc_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_svc_rng2.fit(X2_rng_train, y2_rng_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_svc_rng2.best_params_)\n",
        "y_pred_svc_rng_x2 = grid_svc_rng2.predict(X2_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y2_rng_test, y_pred_svc_rng_x2, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y2_rng_test, y_pred_svc_rng_x2))\n",
        "print(classification_report(y2_rng_test, y_pred_svc_rng_x2))\n",
        "\n",
        "plot_validation_curve(grid_svc_rng2.best_estimator_, X2_rng_train, y2_rng_train, 'C', [0.1, 1, 10], scoring='f1_macro')\n",
        "plot_learning_curve(grid_svc_rng2.best_estimator_, X2_rng_train, y2_rng_train, scoring='f1_macro')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "on-TMUe8W3LF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "on-TMUe8W3LF",
        "outputId": "4e842508-1e86-4fbd-c8ce-d8d981fe594f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# MODELO Decision Tree - Categorización (X1_rng)\n",
        "print(\"\\n=== Decision Tree RNG X1 ===\")\n",
        "dt_rng = DecisionTreeClassifier(random_state=42)\n",
        "dt_rng_params = {'max_depth': [3, 5, 10, None]}\n",
        "grid_dt_rng = GridSearchCV(dt_rng, dt_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_dt_rng.fit(X1_rng_train, y1_rng_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_dt_rng.best_params_)\n",
        "y_pred_dt_rng_x1 = grid_dt_rng.predict(X1_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y1_rng_test, y_pred_dt_rng_x1, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y1_rng_test, y_pred_dt_rng_x1))\n",
        "print(classification_report(y1_rng_test, y_pred_dt_rng_x1))\n",
        "\n",
        "plot_validation_curve(grid_dt_rng.best_estimator_, X1_rng_train, y1_rng_train, 'max_depth', [3, 5, 10, None], scoring='f1_macro')\n",
        "plot_learning_curve(grid_dt_rng.best_estimator_, X1_rng_train, y1_rng_train, scoring='f1_macro')\n",
        "plot_feature_importance(grid_dt_rng.best_estimator_, tf_X1_rng)\n",
        "\n",
        "# MODELO Decision Tree - Categorización (X2_rng)\n",
        "print(\"\\n=== Decision Tree RNG X2 ===\")\n",
        "grid_dt_rng2 = GridSearchCV(dt_rng, dt_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_dt_rng2.fit(X2_rng_train, y2_rng_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_dt_rng2.best_params_)\n",
        "y_pred_dt_rng_x2 = grid_dt_rng2.predict(X2_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y2_rng_test, y_pred_dt_rng_x2, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y2_rng_test, y_pred_dt_rng_x2))\n",
        "print(classification_report(y2_rng_test, y_pred_dt_rng_x2))\n",
        "\n",
        "plot_validation_curve(grid_dt_rng2.best_estimator_, X2_rng_train, y2_rng_train, 'max_depth', [3, 5, 10, None], scoring='f1_macro')\n",
        "plot_learning_curve(grid_dt_rng2.best_estimator_, X2_rng_train, y2_rng_train, scoring='f1_macro')\n",
        "plot_feature_importance(grid_dt_rng2.best_estimator_, tf_X2_rng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DJ42tkDJ8Dyl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DJ42tkDJ8Dyl",
        "outputId": "2bb9accc-a09b-4634-c1d8-3b2ccf177638"
      },
      "outputs": [],
      "source": [
        "# MODELO Random Forest - Categorización (X1_rng)\n",
        "print(\"\\n=== Random Forest RNG X1 ===\")\n",
        "rf_rng = RandomForestClassifier(random_state=42)\n",
        "rf_rng_params = {'n_estimators': [50, 100, 150]}\n",
        "grid_rf_rng = GridSearchCV(rf_rng, rf_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_rf_rng.fit(X1_rng_train, y1_rng_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_rf_rng.best_params_)\n",
        "y_pred_rf_rng_x1 = grid_rf_rng.predict(X1_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y1_rng_test, y_pred_rf_rng_x1, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y1_rng_test, y_pred_rf_rng_x1))\n",
        "print(classification_report(y1_rng_test, y_pred_rf_rng_x1))\n",
        "\n",
        "plot_validation_curve(grid_rf_rng.best_estimator_, X1_rng_train, y1_rng_train, 'n_estimators', [50, 100, 150], scoring='f1_macro')\n",
        "plot_learning_curve(grid_rf_rng.best_estimator_, X1_rng_train, y1_rng_train, scoring='f1_macro')\n",
        "plot_feature_importance(grid_rf_rng.best_estimator_, tf_X1_rng)\n",
        "\n",
        "# MODELO Random Forest - Categorización (X2_rng)\n",
        "print(\"\\n=== Random Forest RNG X2 ===\")\n",
        "grid_rf_rng2 = GridSearchCV(rf_rng, rf_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_rf_rng2.fit(X2_rng_train, y2_rng_train)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_rf_rng2.best_params_)\n",
        "y_pred_rf_rng_x2 = grid_rf_rng2.predict(X2_rng_test)\n",
        "print(\"F1 Macro:\", f1_score(y2_rng_test, y_pred_rf_rng_x2, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y2_rng_test, y_pred_rf_rng_x2))\n",
        "print(classification_report(y2_rng_test, y_pred_rf_rng_x2))\n",
        "\n",
        "plot_validation_curve(grid_rf_rng2.best_estimator_, X2_rng_train, y2_rng_train, 'n_estimators', [50, 100, 150], scoring='f1_macro')\n",
        "plot_learning_curve(grid_rf_rng2.best_estimator_, X2_rng_train, y2_rng_train, scoring='f1_macro')\n",
        "plot_feature_importance(grid_rf_rng2.best_estimator_, tf_X2_rng)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WL0v1Lq4_DwY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WL0v1Lq4_DwY",
        "outputId": "7b8ca111-958f-48d2-e8e2-e47e7bad9c95"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "# Encode the target variables for XGBoost\n",
        "le = LabelEncoder()\n",
        "y1_rng_train_encoded = le.fit_transform(y1_rng_train)\n",
        "y2_rng_train_encoded = le.transform(y2_rng_train)\n",
        "\n",
        "# XGBoost - Categorización (X1_rng)\n",
        "print(\"\\n=== XGBoost RNG X1 ===\")\n",
        "# Use the encoded target variable for fitting XGBoost\n",
        "xgb_rng = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_rng_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.05, 0.1, 0.2]}\n",
        "grid_xgb_rng = GridSearchCV(xgb_rng, xgb_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_xgb_rng.fit(X1_rng_train, y1_rng_train_encoded)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_xgb_rng.best_params_)\n",
        "# Predict and evaluate using the original test set y and encoded training predictions\n",
        "y_pred_xgb_rng_x1_encoded = grid_xgb_rng.predict(X1_rng_test)\n",
        "y_pred_xgb_rng_x1 = le.inverse_transform(y_pred_xgb_rng_x1_encoded) # Inverse transform predictions for evaluation\n",
        "print(\"F1 Macro:\", f1_score(y1_rng_test, y_pred_xgb_rng_x1, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y1_rng_test, y_pred_xgb_rng_x1))\n",
        "print(classification_report(y1_rng_test, y_pred_xgb_rng_x1))\n",
        "\n",
        "plot_validation_curve(grid_xgb_rng.best_estimator_, X1_rng_train, y1_rng_train_encoded, 'n_estimators', [50, 100, 150], scoring='f1_macro')\n",
        "plot_learning_curve(grid_xgb_rng.best_estimator_, X1_rng_train, y1_rng_train_encoded, scoring='f1_macro')\n",
        "plot_feature_importance(grid_xgb_rng.best_estimator_, tf_X1_rng)\n",
        "\n",
        "# XGBoost - Categorización (X2_rng)\n",
        "print(\"\\n=== XGBoost RNG X2 ===\")\n",
        "# Use the encoded target variable for fitting XGBoost\n",
        "grid_xgb_rng2 = GridSearchCV(xgb_rng, xgb_rng_params, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "grid_xgb_rng2.fit(X2_rng_train, y2_rng_train_encoded)\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_xgb_rng2.best_params_)\n",
        "# Predict and evaluate using the original test set y and encoded training predictions\n",
        "y_pred_xgb_rng_x2_encoded = grid_xgb_rng2.predict(X2_rng_test)\n",
        "y_pred_xgb_rng_x2 = le.inverse_transform(y_pred_xgb_rng_x2_encoded) # Inverse transform predictions for evaluation\n",
        "print(\"F1 Macro:\", f1_score(y2_rng_test, y_pred_xgb_rng_x2, average='macro'))\n",
        "print(\"Accuracy:\", accuracy_score(y2_rng_test, y_pred_xgb_rng_x2))\n",
        "print(classification_report(y2_rng_test, y_pred_xgb_rng_x2))\n",
        "\n",
        "plot_validation_curve(grid_xgb_rng2.best_estimator_, X2_rng_train, y2_rng_train_encoded, 'n_estimators', [50, 100, 150], scoring='f1_macro')\n",
        "plot_learning_curve(grid_xgb_rng2.best_estimator_, X2_rng_train, y2_rng_train_encoded, scoring='f1_macro')\n",
        "plot_feature_importance(grid_xgb_rng2.best_estimator_, tf_X2_rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UcWoccMdYYq_",
      "metadata": {
        "id": "UcWoccMdYYq_"
      },
      "source": [
        "### 4.4.1. Balance General de Resultados\n",
        "\n",
        "Se evaluaron cinco algoritmos de clasificación multiclase para predecir el rango de días de permanencia de un empleado en la empresa: K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), Árbol de Decisión, Random Forest y XGBoost. Los rangos definidos fueron: **0–90**, **91–180**, **181–365** y **>365** días. Cada modelo fue entrenado con dos subconjuntos de características (X1 y X2) y se evaluó con métricas como **F1 Macro**, **Accuracy**, y reportes completos de clasificación, así como curvas de validación, aprendizaje y análisis de importancia de características.\n",
        "\n",
        "A continuación, se presenta un resumen comparativo de los resultados obtenidos para cada modelo:\n",
        "\n",
        "| Modelo              | Conjunto | F1 Macro | Accuracy | Observación Clave                           |\n",
        "|---------------------|----------|----------|----------|---------------------------------------------|\n",
        "| **KNN**             | X1       | 0.545    | 0.548    | Desempeño equilibrado, destaca clase 91–180 |\n",
        "|                     | X2       | 0.501    | 0.501    | Rendimiento más bajo, mayor confusión       |\n",
        "| **SVC**             | X1       | 0.550    | 0.546    | Buen desempeño en clase >365                |\n",
        "|                     | X2       | 0.410    | 0.408    | Alto descenso, inestabilidad                |\n",
        "| **Árbol de Decisión**| X1      | 0.501    | 0.501    | Equilibrado pero sin sobresalir             |\n",
        "|                     | X2       | 0.473    | 0.471    | Baja diferenciación entre clases            |\n",
        "| **Random Forest**   | X1       | **0.580**| **0.578**| Mejor resultado general, buena generalización |\n",
        "|                     | X2       | 0.513    | 0.511    | Desempeño moderado, buen recall en >365     |\n",
        "| **XGBoost**         | X1       | 0.556    | 0.557    | Alta robustez, destaca en clases medias     |\n",
        "|                     | X2       | 0.519    | 0.519    | Comportamiento estable pero inferior        |\n",
        "\n",
        "---\n",
        "\n",
        "### 4.4.2. Modelo Seleccionado\n",
        "\n",
        ">  **Random Forest con el conjunto de variables X1**\n",
        "\n",
        "Este modelo fue el que alcanzó el mayor F1 Macro (0.580) y precisión general (accuracy de 0.578), lo que indica una adecuada capacidad de clasificación en todos los rangos definidos. Además, su curva de aprendizaje mostró una ganancia progresiva sin señales críticas de sobreajuste, y la curva de validación mantuvo estabilidad incluso con variaciones en el número de árboles.\n",
        "\n",
        "Otro aspecto destacable es su consistencia para las cuatro clases, en especial para los rangos intermedios (91–365 días), clave para anticipar posibles salidas tempranas o estabilizaciones laborales.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.4.3. Aplicabilidad Real del Modelo\n",
        "\n",
        "Este modelo puede tener usos prácticos significativos en:\n",
        "\n",
        "- **Priorización de esfuerzos de retención** con base en la categoría de permanencia predicha.\n",
        "- **Diseño de estrategias segmentadas** de onboarding, formación o entrevistas de seguimiento según el riesgo de salida.\n",
        "- **Análisis preventivo de talento** dentro del sistema de People Analytics, aportando insumos para la toma de decisiones.\n",
        "\n",
        "Su precisión y balance lo hacen útil para detección temprana y planificación de intervenciones por parte del área de talento humano, en especial si se complementa con datos adicionales cualitativos.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.4.4. Limitaciones y Recomendaciones Futuras\n",
        "\n",
        "#### Limitaciones del Estudio\n",
        "\n",
        "- **Limitada granularidad** en los rangos definidos: aunque los cuatro intervalos de tiempo cubren escenarios críticos, podrían beneficiarse de mayor resolución o enfoque continuo.\n",
        "- **Falta de contexto motivacional**: factores como satisfacción laboral, percepciones de liderazgo o intenciones declaradas no están presentes en los datos, limitando explicabilidad.\n",
        "- **Clase >365 subrepresentada** en desempeño: modelos tienden a confundir esta clase con 91–180, lo que puede afectar planes de retención.\n",
        "- **Riesgo de sobreajuste en algunos modelos** como Random Forest y SVC, especialmente evidenciado por sus curvas de validación y aprendizaje.\n",
        "\n",
        "#### Recomendaciones para el Futuro\n",
        "\n",
        "1. **Mejorar las variables predictoras** mediante encuestas internas o herramientas de feedback continuo que capturen factores emocionales y contextuales.\n",
        "2. **Incorporar técnicas de explicabilidad** (ej. SHAP, LIME) para obtener insights interpretables a nivel individual o por subgrupo.\n",
        "3. **Explorar modelos ordinales o regresivos**, dado que las clases tienen un orden natural; esto podría mejorar la sensibilidad y coherencia del modelo.\n",
        "4. **Monitorear el drift** de datos en producción, actualizando el modelo periódicamente para adaptarse a cambios en políticas, liderazgo o clima organizacional.\n",
        "5. **Ajustar las clases si se detecta polarización**: por ejemplo, combinar categorías cercanas si no se pueden distinguir de manera robusta.\n",
        "\n",
        "---\n",
        "\n",
        "Esta sección cierra el análisis multiclase destacando que, aunque los modelos muestran rendimientos útiles, se requiere una mirada integral que complemente lo técnico con dimensiones humanas, organizacionales y éticas para su implementación efectiva.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "itTtN7BMQQrn",
      "metadata": {
        "id": "itTtN7BMQQrn"
      },
      "source": [
        "## **4.5. Clasificación binaria 2: Predicción de renuncia temprana**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cAbiRq8wDW0N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cAbiRq8wDW0N",
        "outputId": "b00ef4ee-8743-4b5a-9ee1-31949db11566"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 1: Árbol de decisión -----------\n",
        "print(\"\\n=== Decision Tree X1 ===\")\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree_params = {'max_depth': [3, 5, 10, None], 'min_samples_split': [2, 5]}\n",
        "grid_tree = GridSearchCV(tree, tree_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_tree.fit(X1_bin_rng_train, y1_bin_rng_train)\n",
        "\n",
        "print(\"Mejores params Árbol:\", grid_tree.best_params_)\n",
        "y_pred = grid_tree.predict(X1_bin_rng_test)\n",
        "print(\"F1:\", f1_score(y1_bin_rng_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y1_bin_rng_test, y_pred))\n",
        "print(classification_report(y1_bin_rng_test, y_pred))\n",
        "\n",
        "plot_validation_curve(tree, X1_bin_rng_train, y1_bin_rng_train, 'max_depth', [3, 5, 10, None])\n",
        "plot_learning_curve(grid_tree.best_estimator_, X1_bin_rng_train, y1_bin_rng_train)\n",
        "plot_roc_curve(grid_tree.best_estimator_, X1_bin_rng_test, y1_bin_rng_test)\n",
        "plot_feature_importance(grid_tree.best_estimator_, tf_X1_bin_rng)\n",
        "\n",
        "print(\"\\n=== Decision Tree X2 ===\")\n",
        "grid_tree = GridSearchCV(tree, tree_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_tree.fit(X2_bin_rng_train, y2_bin_rng_train)\n",
        "\n",
        "print(\"Mejores params Árbol:\", grid_tree.best_params_)\n",
        "y_pred = grid_tree.predict(X2_bin_rng_test)\n",
        "print(\"F1:\", f1_score(y2_bin_rng_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y2_bin_rng_test, y_pred))\n",
        "print(classification_report(y2_bin_rng_test, y_pred))\n",
        "\n",
        "plot_validation_curve(tree, X2_bin_rng_train, y2_bin_rng_train, 'max_depth', [3, 5, 10, None])\n",
        "plot_learning_curve(grid_tree.best_estimator_, X2_bin_rng_train, y2_bin_rng_train)\n",
        "plot_roc_curve(grid_tree.best_estimator_, X2_bin_rng_test, y2_bin_rng_test)\n",
        "plot_feature_importance(grid_tree.best_estimator_, tf_X2_bin_rng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V_1_TriGD7RY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_1_TriGD7RY",
        "outputId": "5780187e-bbdb-46e2-e6fc-2bef10de4834"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 2: Random Forest -----------\n",
        "print(\"\\n=== Random Forest X1 ===\")\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_params = {'n_estimators': [50, 100, 150]}\n",
        "grid_rf = GridSearchCV(rf, rf_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_rf.fit(X1_bin_rng_train, y1_bin_rng_train)\n",
        "\n",
        "print(\"Mejores params RF:\", grid_rf.best_params_)\n",
        "y_pred = grid_rf.predict(X1_bin_rng_test)\n",
        "print(\"F1:\", f1_score(y1_bin_rng_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y1_bin_rng_test, y_pred))\n",
        "print(classification_report(y1_bin_rng_test, y_pred))\n",
        "\n",
        "plot_validation_curve(rf, X1_bin_rng_train, y1_bin_rng_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_rf.best_estimator_, X1_bin_rng_train, y1_bin_rng_train)\n",
        "plot_roc_curve(grid_rf.best_estimator_, X1_bin_rng_test, y1_bin_rng_test)\n",
        "plot_feature_importance(grid_rf.best_estimator_, tf_X1_bin_rng)\n",
        "\n",
        "print(\"\\n=== Random Forest X2 ===\")\n",
        "grid_rf2 = GridSearchCV(rf, rf_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_rf2.fit(X2_bin_rng_train, y2_bin_rng_train)\n",
        "\n",
        "print(\"Mejores params RF:\", grid_rf2.best_params_)\n",
        "y_pred = grid_rf2.predict(X2_bin_rng_test)\n",
        "print(\"F1:\", f1_score(y2_bin_rng_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y2_bin_rng_test, y_pred))\n",
        "print(classification_report(y2_bin_rng_test, y_pred))\n",
        "\n",
        "plot_validation_curve(rf, X2_bin_rng_train, y2_bin_rng_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_rf2.best_estimator_, X2_bin_rng_train, y2_bin_rng_train)\n",
        "plot_roc_curve(grid_rf2.best_estimator_, X2_bin_rng_test, y2_bin_rng_test)\n",
        "plot_feature_importance(grid_rf2.best_estimator_, tf_X2_bin_rng)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cygxWFfEBdv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2cygxWFfEBdv",
        "outputId": "73dfb104-b745-4451-fd2a-eba2523742be"
      },
      "outputs": [],
      "source": [
        "# ----------- MODELO 3: XGBoost -----------\n",
        "print(\"\\n=== XGBoost X1 ===\")\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.05, 0.1, 0.2]}\n",
        "grid_xgb = GridSearchCV(xgb, xgb_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_xgb.fit(X1_bin_rng_train, y1_bin_rng_train)\n",
        "\n",
        "print(\"Mejores params XGB:\", grid_xgb.best_params_)\n",
        "y_pred = grid_xgb.predict(X1_bin_rng_test)\n",
        "print(\"F1:\", f1_score(y1_bin_rng_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y1_bin_rng_test, y_pred))\n",
        "print(classification_report(y1_bin_rng_test, y_pred))\n",
        "\n",
        "plot_validation_curve(grid_xgb.best_estimator_, X1_bin_rng_train, y1_bin_rng_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_xgb.best_estimator_, X1_bin_rng_train, y1_bin_rng_train)\n",
        "plot_roc_curve(grid_xgb.best_estimator_, X1_bin_rng_test, y1_bin_rng_test)\n",
        "plot_feature_importance(grid_xgb.best_estimator_, tf_X1_bin_rng)\n",
        "\n",
        "print(\"\\n=== XGBoost X2 ===\")\n",
        "grid_xgb2 = GridSearchCV(xgb, xgb_params, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_xgb2.fit(X2_bin_rng_train, y2_bin_rng_train)\n",
        "\n",
        "print(\"Mejores params XGB:\", grid_xgb2.best_params_)\n",
        "y_pred = grid_xgb2.predict(X2_bin_rng_test)\n",
        "print(\"F1:\", f1_score(y2_bin_rng_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y2_bin_rng_test, y_pred))\n",
        "print(classification_report(y2_bin_rng_test, y_pred))\n",
        "\n",
        "plot_validation_curve(grid_xgb2.best_estimator_, X2_bin_rng_train, y2_bin_rng_train, 'n_estimators', [50, 100, 150])\n",
        "plot_learning_curve(grid_xgb2.best_estimator_, X2_bin_rng_train, y2_bin_rng_train)\n",
        "plot_roc_curve(grid_xgb2.best_estimator_, X2_bin_rng_test, y2_bin_rng_test)\n",
        "plot_feature_importance(grid_xgb2.best_estimator_, tf_X2_bin_rng)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4mFENoumvCsP",
      "metadata": {
        "id": "4mFENoumvCsP"
      },
      "source": [
        "### 4.5.1. Balance General de Resultados: Deserción Temprana (≤90 días)\n",
        "\n",
        "Ante los limitados resultados obtenidos en la categorización multiclase, se replanteó el problema como clasificación binaria: **¿El empleado desertará en los primeros 90 días?**. Se evaluaron los algoritmos Árbol de Decisión, Random Forest y XGBoost, cada uno entrenado sobre dos conjuntos de variables (X1 y X2). Las métricas principales fueron **F1-score**, **accuracy** y **AUC-ROC**, acompañadas de los respectivos reportes de clasificación y validación cruzada.\n",
        "\n",
        "El resumen comparativo es el siguiente:\n",
        "\n",
        "| Modelo           | Conjunto | F1-score | Accuracy | AUC-ROC | Observación Clave                         |\n",
        "|------------------|----------|----------|----------|---------|--------------------------------------------|\n",
        "| **Árbol Decisión** | X1     | 0.71     | 0.67     | 0.70    | Mejor recall para deserción, balance aceptable |\n",
        "|                  | X2       | 0.67     | 0.67     | 0.67    | Disminución leve en recall y F1            |\n",
        "| **Random Forest**| X1       | **0.75** | **0.75** | 0.83    | Mejor general, balance, y robustez         |\n",
        "|                  | X2       | 0.69     | 0.68     | 0.76    | Baja pero consistente, mejor recall        |\n",
        "| **XGBoost**      | X1       | **0.75** | **0.75** | **0.84**| Alto balance precisión-recall, excelente discriminación |\n",
        "|                  | X2       | 0.73     | 0.72     | 0.79    | Similar al Random Forest pero menor estabilidad |\n",
        "\n",
        "---\n",
        "\n",
        "### 4.5.2. Modelo Seleccionado\n",
        "\n",
        ">  **XGBoost con el conjunto de variables X1**\n",
        "\n",
        "El modelo **XGBoost (X1)** obtuvo el mayor AUC-ROC (0.84) y uno de los mejores F1-score (0.75), lo que indica una excelente capacidad para discriminar entre quienes desertan y quienes permanecen. Además, mantiene un balance entre precisión y recall para ambas clases, sin sobreajuste marcado ni pérdida significativa de sensibilidad en validación cruzada.\n",
        "\n",
        "Aunque el Random Forest presenta métricas casi idénticas y sería también recomendable, XGBoost muestra una mayor robustez ante el desbalance y ligera mejoría en estabilidad.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.5.3. Aplicabilidad Real del Modelo\n",
        "\n",
        "Este modelo tiene un impacto potencial directo en la gestión del talento humano:\n",
        "\n",
        "- **Alertas tempranas de deserción**: permite priorizar acciones en los primeros 90 días, etapa crítica para la retención.\n",
        "- **Personalización de intervenciones**: asignación de mentorías, seguimiento o capacitaciones diferenciadas a quienes presentan mayor riesgo de deserción.\n",
        "- **Optimización del proceso de selección**: refinando filtros y criterios para reducir costos por rotación temprana.\n",
        "- **Integración con dashboards** y sistemas de RRHH para toma de decisiones en tiempo real.\n",
        "\n",
        "La robustez del modelo lo hace apto para un despliegue inicial, especialmente si se complementa con validaciones periódicas y retroalimentación del área de talento.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.5.4. Limitaciones y Recomendaciones Futuras\n",
        "\n",
        "#### Limitaciones del Estudio\n",
        "\n",
        "- **Enfoque dicotómico**: la reducción a dos clases ignora matices importantes en los motivos y trayectorias de deserción.\n",
        "- **Variables cualitativas ausentes**: elementos como clima laboral, percepción de liderazgo, o problemas personales no están modelados.\n",
        "- **Posible sesgo en la definición de deserción**: asumir que todo retiro <90 días es negativo puede no ser representativo de todos los casos.\n",
        "- **Cambios estructurales en la organización**: pueden afectar la validez del modelo si no se reentrena periódicamente.\n",
        "\n",
        "#### Recomendaciones para el Futuro\n",
        "\n",
        "1. **Expandir el set de variables** incluyendo encuestas de satisfacción, motivaciones y expectativas laborales.\n",
        "2. **Implementar técnicas de explicabilidad** (SHAP, LIME) para facilitar la interpretación y acción sobre casos individuales.\n",
        "3. **Monitorear y actualizar el modelo** cada 6-12 meses, especialmente si hay cambios en el proceso de onboarding o reclutamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZqwaozuyNkKP",
      "metadata": {
        "id": "ZqwaozuyNkKP"
      },
      "source": [
        "# **5. Conclusiones Finales del Modelo Predictivo de Permanencia**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nWDxl8C2Z19P",
      "metadata": {
        "id": "nWDxl8C2Z19P"
      },
      "source": [
        "El presente ejercicio de modelado predictivo en recursos humanos dejó aprendizajes valiosos tanto en la dimensión técnica como en la comprensión organizacional de la deserción temprana.\n",
        "\n",
        "Uno de los hitos metodológicos fue la aplicación de **SMOTE** para balancear la clase minoritaria en el problema de clasificación binaria. Esta técnica resultó fundamental para contrarrestar el sesgo inicial hacia la clase mayoritaria, elevando considerablemente los indicadores de F1-score, accuracy y AUC-ROC, y permitiendo a los modelos captar mejor los patrones asociados a la deserción temprana.\n",
        "\n",
        "Los modelos de **Random Forest** y **XGBoost** emergieron como los más robustos y confiables a lo largo de las pruebas. Ambos destacaron por su capacidad para modelar relaciones no lineales y capturar interacciones complejas entre variables, mostrando mayor estabilidad en validación y mejor capacidad de generalización frente a modelos más simples como KNN, SVC o árboles de decisión individuales. En particular, XGBoost se distinguió por su eficiencia y desempeño superior en métricas globales, siendo especialmente competitivo cuando se disponía de un set de variables de mayor calidad y diversidad.\n",
        "\n",
        "A pesar de los logros, el proyecto también evidenció limitaciones importantes. El desempeño predictivo, aunque razonable, estuvo restringido por la **falta de variables cruciales**: aspectos como clima organizacional, calidad del liderazgo, satisfacción personal y contexto socioeconómico no fueron incluidos por la ausencia de datos estructurados al respecto. Esto implicó que la predicción se apoyara excesivamente en variables como sueldo, edad y algunas codificaciones categóricas de cargos y centros de costos, reduciendo el poder explicativo real y la transferibilidad del modelo ante cambios organizacionales o coyunturales.\n",
        "\n",
        "Por otro lado, la categorización en múltiples rangos temporales de permanencia mostró ser mucho más desafiante, reflejando tanto la complejidad del fenómeno como la escasez de variables realmente predictivas. El hecho de que modelos avanzados solo logren desempeños modestos en este esquema resalta la importancia de profundizar en la calidad y el contexto de los datos disponibles antes de esperar capacidades predictivas superiores.\n",
        "\n",
        "Finalmente, el proceso subrayó la importancia de combinar técnicas de ingeniería de datos, interpretación de modelos y comprensión del negocio. Más allá de la métrica obtenida, la utilidad real del modelo reside en su integración responsable con la gestión de talento, el monitoreo permanente de desempeño y la mejora continua apoyada en nuevas fuentes de información.\n",
        "\n",
        "---\n",
        "\n",
        "**En síntesis:**  \n",
        "El camino recorrido confirma que la analítica predictiva en gestión humana tiene gran potencial, pero su éxito depende tanto de la sofisticación técnica como de la calidad y diversidad de datos disponibles. El uso estratégico de técnicas como SMOTE y la elección de modelos avanzados como Random Forest y XGBoost son solo la base; el siguiente salto requerirá enriquecer la base de datos y vincular la analítica a decisiones organizacionales informadas y éticas.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "240qE0KEBnCT",
        "chw_lKRIGoIc"
      ],
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
